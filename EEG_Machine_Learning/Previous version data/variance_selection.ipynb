{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "import itertools\n",
    "import csv , codecs\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def warn(*args, **kwargs): pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "from sklearn import decomposition\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./EEG_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV 파일 생성 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EEG_data_csv(data_dir):\n",
    "    \n",
    "    # Kinds of Power 입력\n",
    "    file_list = os.listdir(data_dir)\n",
    "    file_list.sort()\n",
    "       \n",
    "    global kinds_of_power\n",
    "    kinds_of_power = \"Relative\"\n",
    "    \n",
    "    excel_dir = \"./EEG_data\" + '/' + kinds_of_power\n",
    "    excel_list = sorted(glob.glob(excel_dir+'/[!~]*.xlsx'))\n",
    "    \n",
    "    # EEG_csv_data 디렉토리 생성\n",
    "    csv_dir = \"./EEG_csv_data\"\n",
    "    if not os.path.isdir(csv_dir):\n",
    "        os.mkdir(csv_dir)\n",
    "    \n",
    "    Abs_dir =\"./EEG_csv_data/Abs\"\n",
    "    Relative_dir = \"./EEG_csv_data/Relative\"\n",
    "    \n",
    "    if not os.path.isdir(Abs_dir):\n",
    "        os.mkdir(Abs_dir)\n",
    "    if not os.path.isdir(Relative_dir):\n",
    "        os.mkdir(Relative_dir)\n",
    "    \n",
    "    book = Workbook()\n",
    "    sheet = book.active\n",
    "    \n",
    "    # x축,y축 생성\n",
    "    for i in range (1,21) :\n",
    "        if i < 10 :\n",
    "            sheet['A'+str(i+1)] = 'S0'+str(i)\n",
    "        if i == 10 :\n",
    "            sheet['A'+str(i+1)] = 'S'+str(10)\n",
    "        if i > 10 :\n",
    "            sheet['A'+str(i+1)] = 'S'+str(i)\n",
    "            \n",
    "    for j in range (0,12):\n",
    "        for i in range(1,33):\n",
    "            sheet.cell(row=1, column=160*j+i+1).value = 'ACh' + str(i)\n",
    "            sheet.cell(row=1, column=160*j+i+33).value = 'BCh' + str(i)\n",
    "            sheet.cell(row=1, column=160*j+i+65).value = 'DCh' + str(i)\n",
    "            sheet.cell(row=1, column=160*j+i+97).value = 'GCh' + str(i)\n",
    "            sheet.cell(row=1, column=160*j+i+129).value = 'TCh' + str(i)\n",
    "\n",
    "    # 파일을 순차적으로 열어서 셀 영역을 복사\n",
    "    # j: 엑셀 파일의 수, k: 각 엑셀 파일 당 시트의 수, n: task의 수, l: subject의 수, m: ch1-ch32\n",
    "\n",
    "    for j in range(0,5):\n",
    "        wb = openpyxl.load_workbook(excel_list[j], data_only=True)\n",
    "        wb_sheet = wb.sheetnames\n",
    "        for k in range(0,12):\n",
    "            source = wb[wb_sheet[k]]\n",
    "            for l in range(2, 22):\n",
    "                for m in range(2, 34):\n",
    "                    sheet.cell(row=l,column=160*k+m+32*j).value = source.cell(row=l,column=m).value\n",
    "\n",
    "    # EEG_csv_data 디렉토리에 csv 파일로 저장\n",
    "    if kinds_of_power == \"Abs\":\n",
    "        with open(Abs_dir + str('/') +'Abs_Merged.csv', 'w', newline=\"\") as f:\n",
    "            c = csv.writer(f)\n",
    "            for r in sheet.rows:\n",
    "                c.writerow([cell.value for cell in r])\n",
    "    elif kinds_of_power == \"Relative\":\n",
    "        with open(Relative_dir + str('/') +'Relative_Merged.csv', 'w', newline=\"\") as f:\n",
    "            c = csv.writer(f)\n",
    "            for r in sheet.rows:\n",
    "                c.writerow([cell.value for cell in r])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV 파일에서 Pandas dataframe으로 가져오는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_setting(task, eye , respiratory):\n",
    "    # 성재가 만든 파일 불러오는 경로 입력 및 데이터 프레임으로 불러올것 \n",
    "    ##  Abs, Relative 설정은 여기서 변경하기기\n",
    "    csv_name = \"./EEG_csv_data/Abs/Abs_Merged.csv\"\n",
    "    data = pd.read_csv(csv_name) \n",
    "    data_column = data.columns\n",
    "    \n",
    "    \n",
    "    # 1 back\n",
    "    if task == 0 : \n",
    "        if respiratory == 0 :\n",
    "            data = data[data_column[1:161]]\n",
    "            # 1-back open eye mouse (alpha, beta, delta, gamma, theta   ch(32*5))\n",
    "            \n",
    "            \n",
    "            \n",
    "        elif respiratory == 1 :\n",
    "            data = data[data_column[161:321]]\n",
    "            # 1-back open eye nose (alpha, beta, delta, gamma, theta   ch(32*5))\n",
    "        elif respiratory == 2 :\n",
    "            data = data[data_column[321:481]]\n",
    "            # 1-back open eye mouse o2 (alpha, beta, delta, gamma, theta   ch(32*5))\n",
    "    # 2 back\n",
    "    elif task == 1 : \n",
    "        if respiratory == 0 :\n",
    "            data = data[data_column[481:641]]\n",
    "            # 2-back open eye mouse (alpha, beta, delta, gamma, theta   ch(32*5))\n",
    "        elif respiratory == 1 :\n",
    "            data= data[data_column[641:801]]\n",
    "            # 2-back open eye nose (alpha, beta, delta, gamma, theta   ch(32*5))\n",
    "        elif respiratory == 2 :\n",
    "            data = data[data_column[801:961]]\n",
    "            # 2-back open eye mouse o2 (alpha, beta, delta, gamma, theta   ch(32*5))\n",
    "    #resting\n",
    "    elif task == 2 :\n",
    "        ## eye ==0 close eye\n",
    "        if eye == 0 :\n",
    "            if respiratory == 0 :\n",
    "                data = data[data_column[961:1121]]\n",
    "                # resting open eye mouse (alpha, beta, delta, gamma, theta   ch(32*5))\n",
    "            elif respiratory == 1 :\n",
    "                data = data[data_column[1121:1281]]\n",
    "                # resting open eye nose (alpha, beta, delta, gamma, theta   ch(32*5))\n",
    "            elif respiratory == 2 :\n",
    "                data = data[data_column[1281:1441]]\n",
    "                # resting open eye mouse o2 (alpha, beta, delta, gamma, theta   ch(32*5))\n",
    "        ## eye ==1 open eye\n",
    "        if eye == 1 : \n",
    "            if respiratory == 0 :\n",
    "                data = data[data_column[1441:1601]]\n",
    "                # resting close eye mouse (alpha, beta, delta, gamma, theta   ch(32*5))\n",
    "            elif respiratory == 1 :\n",
    "                data = data[data_column[1601:1761]]\n",
    "                # resting close eye nose (alpha, beta, delta, gamma, theta   ch(32*5))\n",
    "            elif respiratory == 2 :\n",
    "                data = data[data_column[1761:1921]]\n",
    "                # resting close eye mouse o2 (alpha, beta, delta, gamma, theta   ch(32*5))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return data\n",
    "                \n",
    "                \n",
    "# column indexing task condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### task list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B1_M',\n",
       " 'B1_N',\n",
       " 'B1_O2',\n",
       " 'B2_M',\n",
       " 'B2_N',\n",
       " 'B2_O2',\n",
       " 'Rest_EC_M',\n",
       " 'Rest_EC_N',\n",
       " 'Rest_EC_O2',\n",
       " 'Rest_EO_M',\n",
       " 'Rest_EO_N',\n",
       " 'Rest_EO_O2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb = openpyxl.load_workbook(data_dir+ str('/') +'Relative'+str('/')+'R_Alpha.xlsx')\n",
    "wb_sheet = wb.sheetnames\n",
    "wb_sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kinds of Power 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_data_csv(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### task 0 1 2 : 1-back  2-back  rest\n",
    "\n",
    "### eye 0  1    : close eye     open eye\n",
    "\n",
    "### respiratory 0 1 2 : mouse nose o2 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset 만드는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_csv():\n",
    "    normalize_power = str(input(\"Relative, Abs :\"))\n",
    "    excel_dir = \"./EEG_data\" + '/' + normalize_power\n",
    "    excel_list = sorted(glob.glob(excel_dir+'/[!~]*.xlsx'))\n",
    "    \n",
    "    subject = int(input(\"subject :\"))\n",
    "    \n",
    "\n",
    "    book = Workbook()\n",
    "    sheet = book.active\n",
    "    sheet.cell(row=1, column=161).value = 'target'\n",
    " \n",
    "    # x축 생성   \n",
    "    for i in range(1,33):\n",
    "        sheet.cell(row=1, column=i).value = 'ACh' + str(i)\n",
    "        sheet.cell(row=1, column=i+32).value = 'BCh' + str(i)\n",
    "        sheet.cell(row=1, column=i+64).value = 'DCh' + str(i)\n",
    "        sheet.cell(row=1, column=i+96).value = 'GCh' + str(i)\n",
    "        sheet.cell(row=1, column=i+128).value = 'TCh' + str(i)\n",
    "        \n",
    "    # 파일을 순차적으로 열어서 셀 영역을 복사\n",
    "    for j in range(0,5):\n",
    "        wb = openpyxl.load_workbook(excel_list[j], data_only=True)\n",
    "        wb_sheet = wb.sheetnames\n",
    "        for k in range(0,12):\n",
    "            source = wb[wb_sheet[k]]\n",
    "            for l in range(2, 22):\n",
    "                for m in range(2, 34):\n",
    "                    sheet.cell(row=20*k+l,column=32*j+m-1).value = source.cell(row=l,column=m).value\n",
    "        \n",
    "\n",
    "    with open('./dataset_eeg.csv', 'w', newline=\"\") as f:\n",
    "        c = csv.writer(f)\n",
    "        for r in sheet.rows:\n",
    "            c.writerow([cell.value for cell in r])\n",
    "            \n",
    "    df = pd.read_csv('./dataset_eeg.csv')\n",
    "    df[df =='                      NaN'] =np.nan\n",
    "    df = df.fillna(0.0).astype('float64')\n",
    "    pd.options.mode.chained_assignment = None\n",
    "\n",
    "    df[\"target\"][0*subject:1*subject] = \"010\"\n",
    "    df[\"target\"][1*subject:2*subject] = \"011\"\n",
    "    df[\"target\"][2*subject:3*subject] = \"012\"\n",
    "\n",
    "    df[\"target\"][3*subject:4*subject] = \"110\"\n",
    "    df[\"target\"][4*subject:5*subject] = \"111\"\n",
    "    df[\"target\"][5*subject:6*subject] = \"112\"\n",
    "\n",
    "    df[\"target\"][6*subject:7*subject] = \"200\"\n",
    "    df[\"target\"][7*subject:8*subject] = \"201\"\n",
    "    df[\"target\"][8*subject:9*subject] = \"202\"\n",
    "\n",
    "    df[\"target\"][9*subject:10*subject] = \"210\"\n",
    "    df[\"target\"][10*subject:11*subject] = \"211\"\n",
    "    df[\"target\"][11*subject:12*subject] = \"212\"\n",
    "    df.astype('float64')\n",
    "    df.to_csv('./dataset_eeg.csv')\n",
    "    \n",
    "    return df\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Relative, Abs : Relative\n",
      "subject : 20\n"
     ]
    }
   ],
   "source": [
    "eeg_data = dataset_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACh1</th>\n",
       "      <th>ACh2</th>\n",
       "      <th>ACh3</th>\n",
       "      <th>ACh4</th>\n",
       "      <th>ACh5</th>\n",
       "      <th>ACh6</th>\n",
       "      <th>ACh7</th>\n",
       "      <th>ACh8</th>\n",
       "      <th>ACh9</th>\n",
       "      <th>ACh10</th>\n",
       "      <th>...</th>\n",
       "      <th>TCh24</th>\n",
       "      <th>TCh25</th>\n",
       "      <th>TCh26</th>\n",
       "      <th>TCh27</th>\n",
       "      <th>TCh28</th>\n",
       "      <th>TCh29</th>\n",
       "      <th>TCh30</th>\n",
       "      <th>TCh31</th>\n",
       "      <th>TCh32</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.512153</td>\n",
       "      <td>2.236848</td>\n",
       "      <td>16.237565</td>\n",
       "      <td>8.485316</td>\n",
       "      <td>23.868040</td>\n",
       "      <td>8.095887</td>\n",
       "      <td>61.092520</td>\n",
       "      <td>63.790479</td>\n",
       "      <td>68.686679</td>\n",
       "      <td>69.925212</td>\n",
       "      <td>...</td>\n",
       "      <td>8.735276</td>\n",
       "      <td>0.828638</td>\n",
       "      <td>1.010004</td>\n",
       "      <td>1.778969</td>\n",
       "      <td>6.435780</td>\n",
       "      <td>14.978180</td>\n",
       "      <td>11.507832</td>\n",
       "      <td>11.162954</td>\n",
       "      <td>9.491918</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.539769</td>\n",
       "      <td>4.310226</td>\n",
       "      <td>4.959007</td>\n",
       "      <td>3.965357</td>\n",
       "      <td>7.222414</td>\n",
       "      <td>5.466902</td>\n",
       "      <td>16.751086</td>\n",
       "      <td>19.945360</td>\n",
       "      <td>30.425709</td>\n",
       "      <td>24.128985</td>\n",
       "      <td>...</td>\n",
       "      <td>18.794290</td>\n",
       "      <td>9.741533</td>\n",
       "      <td>7.106003</td>\n",
       "      <td>10.521237</td>\n",
       "      <td>8.559514</td>\n",
       "      <td>18.069939</td>\n",
       "      <td>15.457455</td>\n",
       "      <td>22.764836</td>\n",
       "      <td>22.393518</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.876811</td>\n",
       "      <td>9.070304</td>\n",
       "      <td>3.572186</td>\n",
       "      <td>4.272411</td>\n",
       "      <td>12.559673</td>\n",
       "      <td>19.156709</td>\n",
       "      <td>26.778865</td>\n",
       "      <td>17.134912</td>\n",
       "      <td>53.187562</td>\n",
       "      <td>49.574373</td>\n",
       "      <td>...</td>\n",
       "      <td>11.408656</td>\n",
       "      <td>6.724140</td>\n",
       "      <td>8.721257</td>\n",
       "      <td>10.193054</td>\n",
       "      <td>2.678986</td>\n",
       "      <td>11.522934</td>\n",
       "      <td>11.118133</td>\n",
       "      <td>11.282202</td>\n",
       "      <td>10.760432</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.224107</td>\n",
       "      <td>6.190282</td>\n",
       "      <td>8.670873</td>\n",
       "      <td>8.869054</td>\n",
       "      <td>25.241644</td>\n",
       "      <td>20.749929</td>\n",
       "      <td>40.968150</td>\n",
       "      <td>43.190059</td>\n",
       "      <td>42.509827</td>\n",
       "      <td>41.379676</td>\n",
       "      <td>...</td>\n",
       "      <td>10.493111</td>\n",
       "      <td>4.743475</td>\n",
       "      <td>5.994422</td>\n",
       "      <td>2.769252</td>\n",
       "      <td>5.845854</td>\n",
       "      <td>11.149340</td>\n",
       "      <td>12.461344</td>\n",
       "      <td>12.748985</td>\n",
       "      <td>11.845096</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.441049</td>\n",
       "      <td>19.286110</td>\n",
       "      <td>8.901129</td>\n",
       "      <td>12.888736</td>\n",
       "      <td>7.272771</td>\n",
       "      <td>15.879294</td>\n",
       "      <td>23.182914</td>\n",
       "      <td>38.046045</td>\n",
       "      <td>29.140603</td>\n",
       "      <td>32.524267</td>\n",
       "      <td>...</td>\n",
       "      <td>14.825606</td>\n",
       "      <td>16.428830</td>\n",
       "      <td>15.406232</td>\n",
       "      <td>16.088470</td>\n",
       "      <td>17.454960</td>\n",
       "      <td>18.750681</td>\n",
       "      <td>17.095190</td>\n",
       "      <td>13.764769</td>\n",
       "      <td>13.443134</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>9.377716</td>\n",
       "      <td>6.913374</td>\n",
       "      <td>5.995995</td>\n",
       "      <td>4.562073</td>\n",
       "      <td>6.141009</td>\n",
       "      <td>6.275420</td>\n",
       "      <td>17.190073</td>\n",
       "      <td>19.530794</td>\n",
       "      <td>29.798448</td>\n",
       "      <td>27.170256</td>\n",
       "      <td>...</td>\n",
       "      <td>5.781882</td>\n",
       "      <td>11.865520</td>\n",
       "      <td>10.328138</td>\n",
       "      <td>10.171290</td>\n",
       "      <td>11.796915</td>\n",
       "      <td>15.583215</td>\n",
       "      <td>16.539841</td>\n",
       "      <td>15.194092</td>\n",
       "      <td>14.108681</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>11.906533</td>\n",
       "      <td>10.057115</td>\n",
       "      <td>11.180124</td>\n",
       "      <td>11.478218</td>\n",
       "      <td>14.621087</td>\n",
       "      <td>16.359638</td>\n",
       "      <td>26.560596</td>\n",
       "      <td>24.297633</td>\n",
       "      <td>30.679741</td>\n",
       "      <td>26.798845</td>\n",
       "      <td>...</td>\n",
       "      <td>16.024479</td>\n",
       "      <td>6.548399</td>\n",
       "      <td>6.806564</td>\n",
       "      <td>10.569691</td>\n",
       "      <td>14.455136</td>\n",
       "      <td>15.406702</td>\n",
       "      <td>16.142647</td>\n",
       "      <td>14.712165</td>\n",
       "      <td>14.551317</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>10.335814</td>\n",
       "      <td>8.589677</td>\n",
       "      <td>13.796878</td>\n",
       "      <td>13.048695</td>\n",
       "      <td>25.629270</td>\n",
       "      <td>24.416874</td>\n",
       "      <td>33.204969</td>\n",
       "      <td>34.318945</td>\n",
       "      <td>29.184918</td>\n",
       "      <td>28.485295</td>\n",
       "      <td>...</td>\n",
       "      <td>24.964200</td>\n",
       "      <td>19.061720</td>\n",
       "      <td>18.617480</td>\n",
       "      <td>16.023406</td>\n",
       "      <td>20.075270</td>\n",
       "      <td>26.804320</td>\n",
       "      <td>25.657373</td>\n",
       "      <td>24.098649</td>\n",
       "      <td>19.401579</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>14.781336</td>\n",
       "      <td>13.040448</td>\n",
       "      <td>5.557476</td>\n",
       "      <td>4.101700</td>\n",
       "      <td>19.404795</td>\n",
       "      <td>10.489655</td>\n",
       "      <td>27.480708</td>\n",
       "      <td>24.014191</td>\n",
       "      <td>32.643752</td>\n",
       "      <td>30.794355</td>\n",
       "      <td>...</td>\n",
       "      <td>20.821745</td>\n",
       "      <td>9.054677</td>\n",
       "      <td>14.631369</td>\n",
       "      <td>11.264431</td>\n",
       "      <td>17.292341</td>\n",
       "      <td>19.074393</td>\n",
       "      <td>22.937862</td>\n",
       "      <td>23.429094</td>\n",
       "      <td>12.989213</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.816538</td>\n",
       "      <td>1.050772</td>\n",
       "      <td>0.163984</td>\n",
       "      <td>0.208546</td>\n",
       "      <td>0.376742</td>\n",
       "      <td>0.538038</td>\n",
       "      <td>5.100128</td>\n",
       "      <td>1.964278</td>\n",
       "      <td>7.376851</td>\n",
       "      <td>4.903818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886371</td>\n",
       "      <td>0.319325</td>\n",
       "      <td>0.393430</td>\n",
       "      <td>2.912542</td>\n",
       "      <td>0.339576</td>\n",
       "      <td>3.356003</td>\n",
       "      <td>2.804871</td>\n",
       "      <td>5.997765</td>\n",
       "      <td>6.470478</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ACh1       ACh2       ACh3       ACh4       ACh5       ACh6  \\\n",
       "0     4.512153   2.236848  16.237565   8.485316  23.868040   8.095887   \n",
       "1     4.539769   4.310226   4.959007   3.965357   7.222414   5.466902   \n",
       "2     9.876811   9.070304   3.572186   4.272411  12.559673  19.156709   \n",
       "3     4.224107   6.190282   8.670873   8.869054  25.241644  20.749929   \n",
       "4    18.441049  19.286110   8.901129  12.888736   7.272771  15.879294   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "235   9.377716   6.913374   5.995995   4.562073   6.141009   6.275420   \n",
       "236  11.906533  10.057115  11.180124  11.478218  14.621087  16.359638   \n",
       "237  10.335814   8.589677  13.796878  13.048695  25.629270  24.416874   \n",
       "238  14.781336  13.040448   5.557476   4.101700  19.404795  10.489655   \n",
       "239   0.816538   1.050772   0.163984   0.208546   0.376742   0.538038   \n",
       "\n",
       "          ACh7       ACh8       ACh9      ACh10  ...      TCh24      TCh25  \\\n",
       "0    61.092520  63.790479  68.686679  69.925212  ...   8.735276   0.828638   \n",
       "1    16.751086  19.945360  30.425709  24.128985  ...  18.794290   9.741533   \n",
       "2    26.778865  17.134912  53.187562  49.574373  ...  11.408656   6.724140   \n",
       "3    40.968150  43.190059  42.509827  41.379676  ...  10.493111   4.743475   \n",
       "4    23.182914  38.046045  29.140603  32.524267  ...  14.825606  16.428830   \n",
       "..         ...        ...        ...        ...  ...        ...        ...   \n",
       "235  17.190073  19.530794  29.798448  27.170256  ...   5.781882  11.865520   \n",
       "236  26.560596  24.297633  30.679741  26.798845  ...  16.024479   6.548399   \n",
       "237  33.204969  34.318945  29.184918  28.485295  ...  24.964200  19.061720   \n",
       "238  27.480708  24.014191  32.643752  30.794355  ...  20.821745   9.054677   \n",
       "239   5.100128   1.964278   7.376851   4.903818  ...   0.886371   0.319325   \n",
       "\n",
       "         TCh26      TCh27      TCh28      TCh29      TCh30      TCh31  \\\n",
       "0     1.010004   1.778969   6.435780  14.978180  11.507832  11.162954   \n",
       "1     7.106003  10.521237   8.559514  18.069939  15.457455  22.764836   \n",
       "2     8.721257  10.193054   2.678986  11.522934  11.118133  11.282202   \n",
       "3     5.994422   2.769252   5.845854  11.149340  12.461344  12.748985   \n",
       "4    15.406232  16.088470  17.454960  18.750681  17.095190  13.764769   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "235  10.328138  10.171290  11.796915  15.583215  16.539841  15.194092   \n",
       "236   6.806564  10.569691  14.455136  15.406702  16.142647  14.712165   \n",
       "237  18.617480  16.023406  20.075270  26.804320  25.657373  24.098649   \n",
       "238  14.631369  11.264431  17.292341  19.074393  22.937862  23.429094   \n",
       "239   0.393430   2.912542   0.339576   3.356003   2.804871   5.997765   \n",
       "\n",
       "         TCh32  target  \n",
       "0     9.491918     010  \n",
       "1    22.393518     010  \n",
       "2    10.760432     010  \n",
       "3    11.845096     010  \n",
       "4    13.443134     010  \n",
       "..         ...     ...  \n",
       "235  14.108681     212  \n",
       "236  14.551317     212  \n",
       "237  19.401579     212  \n",
       "238  12.989213     212  \n",
       "239   6.470478     212  \n",
       "\n",
       "[240 rows x 161 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACh1 0.007587008417389649\n",
      "ACh2 0.006152328393046351\n",
      "ACh3 0.007018916110587065\n",
      "ACh4 0.0059285172498349985\n",
      "ACh5 0.005157037900518623\n",
      "ACh6 0.00579162297296112\n",
      "ACh7 0.006013415786220678\n",
      "ACh8 0.006593112809956641\n",
      "ACh9 0.009029062058432543\n",
      "ACh10 0.008616784800142798\n",
      "ACh11 0.006244665798661268\n",
      "ACh12 0.006227855505849455\n",
      "ACh13 0.007221147042214655\n",
      "ACh14 0.005768580241686409\n",
      "ACh15 0.0053891525570906726\n",
      "ACh16 0.00522237589741898\n",
      "ACh17 0.0065570466817298475\n",
      "ACh18 0.0\n",
      "ACh19 0.005722865960595451\n",
      "ACh20 0.007588661716306719\n",
      "ACh21 0.005161212297639085\n",
      "ACh22 0.005844640799209327\n",
      "ACh23 0.005477401497389924\n",
      "ACh24 0.005007400735563717\n",
      "ACh25 0.006112367231673394\n",
      "ACh26 0.005482229431378669\n",
      "ACh27 0.006714468352178618\n",
      "ACh28 0.006608903935856279\n",
      "ACh29 0.006510443049839862\n",
      "ACh30 0.005723890570008527\n",
      "ACh31 0.006989312385059141\n",
      "ACh32 0.0051499842494916945\n",
      "BCh1 0.007423557639470103\n",
      "BCh2 0.008373374676955987\n",
      "BCh3 0.006691755227578509\n",
      "BCh4 0.006802654423096436\n",
      "BCh5 0.007102791105380151\n",
      "BCh6 0.006984592552588529\n",
      "BCh7 0.0052142516306009955\n",
      "BCh8 0.006013452710413941\n",
      "BCh9 0.004534401990739562\n",
      "BCh10 0.005274085636895108\n",
      "BCh11 0.006164075323003153\n",
      "BCh12 0.00546315834926091\n",
      "BCh13 0.00591506021671856\n",
      "BCh14 0.0055028495063833794\n",
      "BCh15 0.005005579197526425\n",
      "BCh16 0.004580766729976627\n",
      "BCh17 0.006052264432315645\n",
      "BCh18 0.0\n",
      "BCh19 0.004985992116005188\n",
      "BCh20 0.003911081516153692\n",
      "BCh21 0.006054436499288866\n",
      "BCh22 0.004524259920004304\n",
      "BCh23 0.004855922495135203\n",
      "BCh24 0.005422979226857066\n",
      "BCh25 0.006805299714461507\n",
      "BCh26 0.006850420538192666\n",
      "BCh27 0.006537927560269352\n",
      "BCh28 0.00581127293010873\n",
      "BCh29 0.0057393928153943894\n",
      "BCh30 0.0058122108563715335\n",
      "BCh31 0.005534082476002783\n",
      "BCh32 0.005643357520329727\n",
      "DCh1 0.006260587014814165\n",
      "DCh2 0.005620201804668202\n",
      "DCh3 0.006709734174150371\n",
      "DCh4 0.007051790718647159\n",
      "DCh5 0.004957925388477451\n",
      "DCh6 0.00626348003444382\n",
      "DCh7 0.005735797111484923\n",
      "DCh8 0.0054937535400185495\n",
      "DCh9 0.0075537182479598255\n",
      "DCh10 0.007545470121568928\n",
      "DCh11 0.0051099884656847176\n",
      "DCh12 0.006207448823894532\n",
      "DCh13 0.0066264308555879165\n",
      "DCh14 0.006762622807171826\n",
      "DCh15 0.00630428999868347\n",
      "DCh16 0.005595132022786524\n",
      "DCh17 0.005377836785126183\n",
      "DCh18 0.0\n",
      "DCh19 0.007706232563192802\n",
      "DCh20 0.00694092173102453\n",
      "DCh21 0.0053494210843182686\n",
      "DCh22 0.00638997845428033\n",
      "DCh23 0.0062535963082076635\n",
      "DCh24 0.006026119770604561\n",
      "DCh25 0.006417286962951748\n",
      "DCh26 0.005696511345391956\n",
      "DCh27 0.005707105063809733\n",
      "DCh28 0.00570967681664043\n",
      "DCh29 0.00570744442068832\n",
      "DCh30 0.006350100692016755\n",
      "DCh31 0.006747970975914229\n",
      "DCh32 0.006305471107644971\n",
      "GCh1 0.009440534657616803\n",
      "GCh2 0.01086837808528248\n",
      "GCh3 0.007515665906149178\n",
      "GCh4 0.009140646980483051\n",
      "GCh5 0.00853073517154278\n",
      "GCh6 0.008236239058902155\n",
      "GCh7 0.010017042778330189\n",
      "GCh8 0.008167595074749033\n",
      "GCh9 0.006705038256892172\n",
      "GCh10 0.006631785772478337\n",
      "GCh11 0.008784943165090625\n",
      "GCh12 0.008184370024095977\n",
      "GCh13 0.007255397778041793\n",
      "GCh14 0.007958832225532245\n",
      "GCh15 0.007369803393315054\n",
      "GCh16 0.007566692308855562\n",
      "GCh17 0.008406513763792206\n",
      "GCh18 0.0\n",
      "GCh19 0.005659572305325835\n",
      "GCh20 0.005861198558992184\n",
      "GCh21 0.009154044394968508\n",
      "GCh22 0.007085632658106036\n",
      "GCh23 0.006953206104417163\n",
      "GCh24 0.00703817506281004\n",
      "GCh25 0.008530870793193354\n",
      "GCh26 0.010348119353492596\n",
      "GCh27 0.009139585842471763\n",
      "GCh28 0.0074581702853471045\n",
      "GCh29 0.007118283828818095\n",
      "GCh30 0.008594007178599653\n",
      "GCh31 0.0067716814922747426\n",
      "GCh32 0.006766397781895198\n",
      "TCh1 0.005821417191638579\n",
      "TCh2 0.006298289177350031\n",
      "TCh3 0.006407339441990443\n",
      "TCh4 0.005773968416413234\n",
      "TCh5 0.005556426035197564\n",
      "TCh6 0.006142079863545395\n",
      "TCh7 0.005002025491680744\n",
      "TCh8 0.005117064476451274\n",
      "TCh9 0.005991927918592709\n",
      "TCh10 0.007100370106254202\n",
      "TCh11 0.00534960351708903\n",
      "TCh12 0.006088843359367572\n",
      "TCh13 0.005493573126171818\n",
      "TCh14 0.0054848496071751495\n",
      "TCh15 0.004714392676065508\n",
      "TCh16 0.004985135132208106\n",
      "TCh17 0.006735285411070147\n",
      "TCh18 0.0\n",
      "TCh19 0.005096630507269834\n",
      "TCh20 0.006644496075615489\n",
      "TCh21 0.006500891683096728\n",
      "TCh22 0.005094700021472007\n",
      "TCh23 0.004331215608934468\n",
      "TCh24 0.0062009425882098065\n",
      "TCh25 0.00712154099966976\n",
      "TCh26 0.007417136900851796\n",
      "TCh27 0.007111780022132003\n",
      "TCh28 0.007119960260002443\n",
      "TCh29 0.005681871432212793\n",
      "TCh30 0.0051500375662923\n",
      "TCh31 0.0057056018865272095\n",
      "TCh32 0.006817678276323998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X = eeg_data.iloc[:,0:-1]\n",
    "X1=np.array(X)\n",
    "Y = eeg_data['target']\n",
    "Y1= np.array(Y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, Y1, random_state=42)\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=1000, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "for name, score in zip(X.columns.tolist(), rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **train set에 관한 feature 160의 variances 계산**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACh1 24.9742856955811 0.007587008417389649\n",
      "ACh2 28.494850761797917 0.006152328393046351\n",
      "ACh3 29.136138202772436 0.007018916110587065\n",
      "ACh4 29.220829872925744 0.0059285172498349985\n",
      "ACh5 46.702028656619184 0.005157037900518623\n",
      "ACh6 41.84621867765508 0.00579162297296112\n",
      "ACh7 68.1628038064602 0.006013415786220678\n",
      "ACh8 73.23761846346146 0.006593112809956641\n",
      "ACh9 73.49989886881383 0.009029062058432543\n",
      "ACh10 77.4780650005016 0.008616784800142798\n",
      "ACh11 35.559490246336196 0.006244665798661268\n",
      "ACh12 33.717913934066786 0.006227855505849455\n",
      "ACh13 46.63048357284951 0.007221147042214655\n",
      "ACh14 51.30137928883607 0.005768580241686409\n",
      "ACh15 65.22511440757512 0.0053891525570906726\n",
      "ACh16 69.3518316795425 0.00522237589741898\n",
      "ACh17 41.32121977982774 0.0065570466817298475\n",
      "ACh18 0.0 0.0\n",
      "ACh19 57.342975191284935 0.005722865960595451\n",
      "ACh20 77.96187387432465 0.007588661716306719\n",
      "ACh21 35.531973064443754 0.005161212297639085\n",
      "ACh22 37.39653776587193 0.005844640799209327\n",
      "ACh23 61.46535640790887 0.005477401497389924\n",
      "ACh24 69.3477840088166 0.005007400735563717\n",
      "ACh25 29.396364322867388 0.006112367231673394\n",
      "ACh26 26.570234441178638 0.005482229431378669\n",
      "ACh27 27.74054642089893 0.006714468352178618\n",
      "ACh28 33.91425935771779 0.006608903935856279\n",
      "ACh29 42.45911487186272 0.006510443049839862\n",
      "ACh30 40.9332103794992 0.005723890570008527\n",
      "ACh31 54.220124393228765 0.006989312385059141\n",
      "ACh32 53.8620931554721 0.0051499842494916945\n",
      "BCh1 40.2752471423537 0.007423557639470103\n",
      "BCh2 33.03521875182867 0.008373374676955987\n",
      "BCh3 23.365622030345584 0.006691755227578509\n",
      "BCh4 45.34440524665634 0.006802654423096436\n",
      "BCh5 33.24579219727195 0.007102791105380151\n",
      "BCh6 35.234768213602656 0.006984592552588529\n",
      "BCh7 24.323004997567562 0.0052142516306009955\n",
      "BCh8 26.38122751413751 0.006013452710413941\n",
      "BCh9 25.22845729954636 0.004534401990739562\n",
      "BCh10 26.086763721330286 0.005274085636895108\n",
      "BCh11 34.70715934415803 0.006164075323003153\n",
      "BCh12 40.23643736189543 0.00546315834926091\n",
      "BCh13 29.69736517083723 0.00591506021671856\n",
      "BCh14 33.29950750495097 0.0055028495063833794\n",
      "BCh15 27.49593832723266 0.005005579197526425\n",
      "BCh16 28.108752293862253 0.004580766729976627\n",
      "BCh17 30.14407136776018 0.006052264432315645\n",
      "BCh18 0.0 0.0\n",
      "BCh19 28.41671688687056 0.004985992116005188\n",
      "BCh20 26.918286189442153 0.003911081516153692\n",
      "BCh21 30.734891004792832 0.006054436499288866\n",
      "BCh22 54.86002399186617 0.004524259920004304\n",
      "BCh23 26.0561894480609 0.004855922495135203\n",
      "BCh24 30.836461705201813 0.005422979226857066\n",
      "BCh25 46.60543594386136 0.006805299714461507\n",
      "BCh26 44.562199988712685 0.006850420538192666\n",
      "BCh27 26.033049359620637 0.006537927560269352\n",
      "BCh28 34.42276751252703 0.00581127293010873\n",
      "BCh29 29.63520590265111 0.0057393928153943894\n",
      "BCh30 33.04386631823082 0.0058122108563715335\n",
      "BCh31 29.00963781402005 0.005534082476002783\n",
      "BCh32 31.61766727414163 0.005643357520329727\n",
      "DCh1 97.5550226314804 0.006260587014814165\n",
      "DCh2 74.2196895098298 0.005620201804668202\n",
      "DCh3 69.44232183012822 0.006709734174150371\n",
      "DCh4 79.2008010621232 0.007051790718647159\n",
      "DCh5 79.309216499341 0.004957925388477451\n",
      "DCh6 81.59600958666779 0.00626348003444382\n",
      "DCh7 71.23329506567049 0.005735797111484923\n",
      "DCh8 79.55092283094669 0.0054937535400185495\n",
      "DCh9 72.6666626136853 0.0075537182479598255\n",
      "DCh10 78.58497966662551 0.007545470121568928\n",
      "DCh11 76.03842619936009 0.0051099884656847176\n",
      "DCh12 85.37776483463941 0.006207448823894532\n",
      "DCh13 73.0323791646618 0.0066264308555879165\n",
      "DCh14 73.6293048839211 0.006762622807171826\n",
      "DCh15 66.3917356773346 0.00630428999868347\n",
      "DCh16 70.99500879067949 0.005595132022786524\n",
      "DCh17 73.1805084479648 0.005377836785126183\n",
      "DCh18 0.0 0.0\n",
      "DCh19 63.96960449765949 0.007706232563192802\n",
      "DCh20 80.05109349469059 0.00694092173102453\n",
      "DCh21 72.56896548475962 0.0053494210843182686\n",
      "DCh22 88.80142162575545 0.00638997845428033\n",
      "DCh23 74.78382240475031 0.0062535963082076635\n",
      "DCh24 78.09544932840168 0.006026119770604561\n",
      "DCh25 84.0458435054508 0.006417286962951748\n",
      "DCh26 75.4571959377313 0.005696511345391956\n",
      "DCh27 67.99616355059712 0.005707105063809733\n",
      "DCh28 74.625939837614 0.00570967681664043\n",
      "DCh29 71.98422937993 0.00570744442068832\n",
      "DCh30 81.08845498158232 0.006350100692016755\n",
      "DCh31 54.29258796718481 0.006747970975914229\n",
      "DCh32 58.966310659051516 0.006305471107644971\n",
      "GCh1 27.073295446241197 0.009440534657616803\n",
      "GCh2 28.784784983214927 0.01086837808528248\n",
      "GCh3 9.159479980768072 0.007515665906149178\n",
      "GCh4 20.600548500662924 0.009140646980483051\n",
      "GCh5 30.087220867405236 0.00853073517154278\n",
      "GCh6 30.928735974540654 0.008236239058902155\n",
      "GCh7 3.356059153693877 0.010017042778330189\n",
      "GCh8 2.735143669948519 0.008167595074749033\n",
      "GCh9 6.697307014270025 0.006705038256892172\n",
      "GCh10 6.935395544748865 0.006631785772478337\n",
      "GCh11 25.68691568979741 0.008784943165090625\n",
      "GCh12 29.718686060645982 0.008184370024095977\n",
      "GCh13 12.185144169456425 0.007255397778041793\n",
      "GCh14 9.588247618184685 0.007958832225532245\n",
      "GCh15 2.076523507014014 0.007369803393315054\n",
      "GCh16 2.1923696222993128 0.007566692308855562\n",
      "GCh17 8.968569204678454 0.008406513763792206\n",
      "GCh18 0.0 0.0\n",
      "GCh19 2.9094545211778753 0.005659572305325835\n",
      "GCh20 6.54138654608659 0.005861198558992184\n",
      "GCh21 16.84666581173687 0.009154044394968508\n",
      "GCh22 27.701177710478852 0.007085632658106036\n",
      "GCh23 11.257111004566818 0.006953206104417163\n",
      "GCh24 12.583961949136567 0.00703817506281004\n",
      "GCh25 35.27731113622854 0.008530870793193354\n",
      "GCh26 25.287663366026983 0.010348119353492596\n",
      "GCh27 11.814280347385079 0.009139585842471763\n",
      "GCh28 20.60147424401372 0.0074581702853471045\n",
      "GCh29 8.769133661285093 0.007118283828818095\n",
      "GCh30 13.364825519931903 0.008594007178599653\n",
      "GCh31 4.311269816563228 0.0067716814922747426\n",
      "GCh32 5.173206907923305 0.006766397781895198\n",
      "TCh1 36.8898714896174 0.005821417191638579\n",
      "TCh2 34.315786167124486 0.006298289177350031\n",
      "TCh3 39.64622133451689 0.006407339441990443\n",
      "TCh4 33.8101951288977 0.005773968416413234\n",
      "TCh5 43.42679792741317 0.005556426035197564\n",
      "TCh6 38.71584833551932 0.006142079863545395\n",
      "TCh7 36.34803682586656 0.005002025491680744\n",
      "TCh8 36.172202424891545 0.005117064476451274\n",
      "TCh9 36.77259101857129 0.005991927918592709\n",
      "TCh10 36.53437303549075 0.007100370106254202\n",
      "TCh11 39.18801446608301 0.00534960351708903\n",
      "TCh12 37.396042242661665 0.006088843359367572\n",
      "TCh13 37.40753500539386 0.005493573126171818\n",
      "TCh14 35.57383138126325 0.0054848496071751495\n",
      "TCh15 34.13792449090161 0.004714392676065508\n",
      "TCh16 32.72836171097969 0.004985135132208106\n",
      "TCh17 58.54058026056034 0.006735285411070147\n",
      "TCh18 0.0 0.0\n",
      "TCh19 42.48698719800784 0.005096630507269834\n",
      "TCh20 39.3570642096776 0.006644496075615489\n",
      "TCh21 42.296258890728915 0.006500891683096728\n",
      "TCh22 37.574902748223934 0.005094700021472007\n",
      "TCh23 40.775495039126234 0.004331215608934468\n",
      "TCh24 36.989495785624214 0.0062009425882098065\n",
      "TCh25 36.85757434544098 0.00712154099966976\n",
      "TCh26 35.12809588625273 0.007417136900851796\n",
      "TCh27 37.22277633840459 0.007111780022132003\n",
      "TCh28 48.13481613338752 0.007119960260002443\n",
      "TCh29 44.13179917137263 0.005681871432212793\n",
      "TCh30 38.71104542924404 0.0051500375662923\n",
      "TCh31 34.29478010256258 0.0057056018865272095\n",
      "TCh32 30.682524053743595 0.006817678276323998\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, Y1, random_state=42)\n",
    "\n",
    "thresholder=VarianceThreshold()\n",
    "\n",
    "variances=thresholder.fit(X_train)\n",
    "\n",
    "d1_train=dict(zip(X.columns.tolist(), list(variances.variances_)))\n",
    "d2_train=dict(zip(X.columns.tolist(), list(rnd_clf.feature_importances_)))\n",
    "\n",
    "for name, variance, importance in zip(X.columns.tolist(), d1_train.values(), d2_train.values() ):\n",
    "    print(name, variance, importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(x):\n",
    "    return x[1]\n",
    "\n",
    "sorted_d1_train = dict(sorted(d1_train.items(),key=f2,reverse=True))\n",
    "sorted_d2_train = dict(sorted(d2_train.items(),key=f2,reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        varinace  importance\n",
      "DCh1   97.555023    0.006261\n",
      "DCh22  88.801422    0.006390\n",
      "DCh12  85.377765    0.006207\n",
      "DCh25  84.045844    0.006417\n",
      "DCh6   81.596010    0.006263\n",
      "...          ...         ...\n",
      "ACh18   0.000000    0.000000\n",
      "BCh18   0.000000    0.000000\n",
      "DCh18   0.000000    0.000000\n",
      "GCh18   0.000000    0.000000\n",
      "TCh18   0.000000    0.000000\n",
      "\n",
      "[160 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame()\n",
    "\n",
    "#variance가 높은 순으로 ch, importance 정렬\n",
    "df['varinace']=sorted_d1_train.values()\n",
    "df.index=sorted_d1_train.keys()\n",
    "\n",
    "channel=list(sorted_d1_train.keys())\n",
    "importance_list=[]\n",
    "\n",
    "for i in range(0,160):\n",
    "    importance_list.append(sorted_d2_train.get(channel[i]))\n",
    "\n",
    "df['importance']=importance_list\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_csv(\"./train_variance_importance2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>160.000000</td>\n",
       "      <td>160.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.457232</td>\n",
       "      <td>0.006250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23.288306</td>\n",
       "      <td>0.001655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.390278</td>\n",
       "      <td>0.005501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.873017</td>\n",
       "      <td>0.006218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>57.642376</td>\n",
       "      <td>0.007042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>97.555023</td>\n",
       "      <td>0.010868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         variance  importance\n",
       "count  160.000000  160.000000\n",
       "mean    40.457232    0.006250\n",
       "std     23.288306    0.001655\n",
       "min      0.000000    0.000000\n",
       "25%     27.390278    0.005501\n",
       "50%     35.873017    0.006218\n",
       "75%     57.642376    0.007042\n",
       "max     97.555023    0.010868"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature importance의 variance 상관관계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            variance  importance\n",
      "variance    1.000000    0.053026\n",
      "importance  0.053026    1.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lst=np.array(range(320),dtype=np.float).reshape((2,160))\n",
    "\n",
    "lst[0]=list(sorted_d1_train.values())\n",
    "lst[1]=importance_list\n",
    " \n",
    "df=pd.DataFrame({\"variance\":list(sorted_d1_train.values()),\"importance\":importance_list})\n",
    "corr=df.corr(method='pearson')\n",
    "print(corr)\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "df_heatmap = sns.heatmap(corr, cbar = True, annot = True, annot_kws={'size' : 20}, fmt = '.2f', square = True, cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "무작위로 선택된 수천 명의 사람에게 복잡한 질문을 하고 대답을 모으면 많은 경우 전문가의 답보다 이렇게 모은 답이 낫습니다. \n",
    "\n",
    "이를 **대중의 지혜(wisdom of crowd)** 라고 합니다.\n",
    "\n",
    "\n",
    "\n",
    "이와 비슷하게 일련의 예측기로부터 예측을 수집하면 가장 좋은 모델 하나보다 더 좋은 예측을 얻을 수 있습니다. \n",
    "\n",
    "일련의 예측기를 **앙상블(ensemble)** 이라고 부릅니다. \n",
    "\n",
    "\n",
    "Decision tree의 ensemble을 **Random Forest**라고 합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "###    1. 160개의 feature 중에서 Randomforest classification을 통해 Feature importance로 상위 몇 개의 feature를 선택합니다.\n",
    "\n",
    "\n",
    "###    2. 선택한 상위 feature 들을 Linear Discriminant Analysis(LDA)를 적용하여 차원 축소를 진행합니다.\n",
    "\n",
    "\n",
    "###    3. 줄어든 Dimension 상에서 RandomForest와 같은 Enseble Classification을 진행합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Linear Discriminant Analysis (LDA)은 훈련과정에서 클래스 사이를 가장 잘 구분하는 축을 학습합니다. 이 축은 데이터가 투영되는 hyperplane을 정의하는데 사용할 수 있습니다.\n",
    "이 알고리즘의 장점은 projection을 통해 가능한 한 클래스를 멀리 떨어지게 유지하므로 SVM과 같은 다른 classification 알고리즘을 적용하기 전에 차원을 축소시키는데 좋습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest classification을 사용하여 feature importance를 알아냅니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* **RandomForest feature importance는 DecisionTree importance를 feature 별로 평균화해서 feature importance를 구함**\n",
    "\n",
    "    - 최종적으로 feature importance의 합이 1이 되도록 정규화함\n",
    "    \n",
    "    - DecisionTree에서 node 하나의 importance는 다음과 같이 계산함\n",
    "        + \n",
    "        $$\n",
    "        \\frac{\\mathbf{n}_p \\times \\mathbf{I}_p - (\\mathbf{n}_l \\times \\mathbf{I}_l + \\mathbf{n}_r \\times \\mathbf{I}_r )}{\\mathbf{n}}\n",
    "        $$\n",
    "        + $\\mathbf{n}_p$와$\\mathbf{I}_p$는 각각 상위 node의 sample개수와 불순도\n",
    "        + $\\mathbf{n}_l$와 $\\mathbf{I}_l$는 왼쪽 node, $\\mathbf{n}_r$와 $\\mathbf{I}_r$는 오른쪽 node의 sample개수와 불순도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# channel은 feature 이름과 feature importance를 같이 담고 있는 list\n",
    "channel = []\n",
    "# choice된 top feature list\n",
    "choice_feature =[]\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "#   Random forest classification을 사용하여 feature importance를 얻어냄#      \n",
    "#######################################################################\n",
    "X = eeg_data.iloc[:,0:-1]\n",
    "Y = eeg_data['target']\n",
    "X1 = np.array(eeg_data.iloc[:,0:-1])\n",
    "Y1 = np.array(eeg_data['target'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, Y1, random_state=42)\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature importance를 얻어내기 위해 사용한 Randomforest의 정확도\n",
    "rnd_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 얻어낸 feature importance를 이용하여 feature importances가 높은 Channel을 선택합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "print(\"1~155, (feature importance, 'ACh18,BCh18,DCh18,GCh18,TCh18'=0 )\")\n",
    "aa= int(input(\"top feature of number : \" ))\n",
    "feature_list= list(zip(X.columns.tolist(),rnd_clf.feature_importances_))\n",
    "feature_dict= dict(zip(X.columns.tolist(),rnd_clf.feature_importances_))\n",
    "sorted_feature = sorted(feature_dict.values(), reverse=True)\n",
    "top_feature = sorted_feature[0:aa]\n",
    "\n",
    "\n",
    "for i in range(len(feature_list)):\n",
    "    for j in range(len(top_feature)):\n",
    "        if feature_list[i][1] == top_feature[j]:\n",
    "            channel.append(feature_list[i])\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "for i in range(len(channel)):\n",
    "    choice_feature.append(channel[i][0])\n",
    "    \n",
    "#print(choice_feature)\n",
    "choice_feature_df = eeg_data[choice_feature]\n",
    "choice_feature_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Channel(feature)을 feature importance 내림차순으로 정렬합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ch1', 0.03489035224847585),\n",
       " ('Ch2', 0.038242839513376176),\n",
       " ('Ch3', 0.03677712435293869),\n",
       " ('Ch4', 0.03819682592920495),\n",
       " ('Ch5', 0.03390268526106585),\n",
       " ('Ch6', 0.035408378887680475),\n",
       " ('Ch7', 0.02753411947861204),\n",
       " ('Ch8', 0.030664719363380968),\n",
       " ('Ch9', 0.032596507247777254),\n",
       " ('Ch10', 0.037350127066646914),\n",
       " ('Ch11', 0.030410779263039235),\n",
       " ('Ch12', 0.025985618299923928),\n",
       " ('Ch13', 0.032598207081357175),\n",
       " ('Ch14', 0.03359165032059278),\n",
       " ('Ch15', 0.029575586925487354),\n",
       " ('Ch16', 0.026187644509038044),\n",
       " ('Ch17', 0.033384363130639354),\n",
       " ('Ch18', 0.0),\n",
       " ('Ch19', 0.02498439854684391),\n",
       " ('Ch20', 0.03290512798782788),\n",
       " ('Ch21', 0.03176182998008998),\n",
       " ('Ch22', 0.029918302733440122),\n",
       " ('Ch23', 0.029135865956550815),\n",
       " ('Ch24', 0.030241990858975252),\n",
       " ('Ch25', 0.029793875283570838),\n",
       " ('Ch26', 0.03611987385231999),\n",
       " ('Ch27', 0.03609429042794179),\n",
       " ('Ch28', 0.034257896357009744),\n",
       " ('Ch29', 0.0341338445914672),\n",
       " ('Ch30', 0.033235373273846625),\n",
       " ('Ch31', 0.029125918028880524),\n",
       " ('Ch32', 0.030993883241998317)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important = rnd_clf.feature_importances_\n",
    "channel_important =important[0:32]+important[32:64]+important[64:96]+important[96:128]+important[128:160]\n",
    "\n",
    "channel_list = []\n",
    "for i in range(1,len(channel_important)+1):\n",
    "    channel_list.append(\"Ch\"+str(i))\n",
    "channel_list\n",
    "\n",
    "feature_list2= list(zip(channel_list,channel_important))\n",
    "feature_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Ch2', 0.038242839513376176],\n",
       " ['Ch4', 0.03819682592920495],\n",
       " ['Ch10', 0.037350127066646914],\n",
       " ['Ch3', 0.03677712435293869],\n",
       " ['Ch26', 0.03611987385231999],\n",
       " ['Ch27', 0.03609429042794179],\n",
       " ['Ch6', 0.035408378887680475],\n",
       " ['Ch1', 0.03489035224847585],\n",
       " ['Ch28', 0.034257896357009744],\n",
       " ['Ch29', 0.0341338445914672],\n",
       " ['Ch5', 0.03390268526106585],\n",
       " ['Ch14', 0.03359165032059278],\n",
       " ['Ch17', 0.033384363130639354],\n",
       " ['Ch30', 0.033235373273846625],\n",
       " ['Ch20', 0.03290512798782788],\n",
       " ['Ch13', 0.032598207081357175],\n",
       " ['Ch9', 0.032596507247777254],\n",
       " ['Ch21', 0.03176182998008998],\n",
       " ['Ch32', 0.030993883241998317],\n",
       " ['Ch8', 0.030664719363380968],\n",
       " ['Ch11', 0.030410779263039235],\n",
       " ['Ch24', 0.030241990858975252],\n",
       " ['Ch22', 0.029918302733440122],\n",
       " ['Ch25', 0.029793875283570838],\n",
       " ['Ch15', 0.029575586925487354],\n",
       " ['Ch23', 0.029135865956550815],\n",
       " ['Ch31', 0.029125918028880524],\n",
       " ['Ch7', 0.02753411947861204],\n",
       " ['Ch16', 0.026187644509038044],\n",
       " ['Ch12', 0.025985618299923928],\n",
       " ['Ch19', 0.02498439854684391],\n",
       " ['Ch18', 0.0]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_channel2 = []\n",
    "reverse_channel = []\n",
    "sorting_important=[]\n",
    "for i in range(len(feature_list2)):\n",
    "    reverse_channel.append(list(reversed(feature_list2[i])))\n",
    "\n",
    "    \n",
    "\n",
    "sorted_channel2 = sorted(reverse_channel,reverse=True)\n",
    "\n",
    "for i in range(len(feature_list2)):\n",
    "    sorting_important.append(list(reversed(sorted_channel2[i])))\n",
    "    \n",
    "sorting_important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_select ():\n",
    "    \n",
    "    print( \"channel importance\")\n",
    "    print(\"channel num :1 ~ 32\")\n",
    "    \n",
    "    #val = []\n",
    "    \n",
    "    for i in range(len(sorting_important)):\n",
    "        #val.append(sorting_important[i][1])\n",
    "        print( sorting_important[i])\n",
    "        \n",
    "    #print(sum(val))\n",
    "    channel = int(input(\"selecting feature number : \"))\n",
    "    select_channel=sorting_important[0:channel]\n",
    "    \n",
    "    columns_name = []\n",
    "    for i in range(len(select_channel)):\n",
    "        columns_name.append(\"A\"+select_channel[i][0])\n",
    "        columns_name.append(\"B\"+select_channel[i][0])\n",
    "        columns_name.append(\"D\"+select_channel[i][0])\n",
    "        columns_name.append(\"G\"+select_channel[i][0])\n",
    "        columns_name.append(\"T\"+select_channel[i][0])\n",
    "    columns_name = sorted(columns_name)\n",
    "    df = eeg_data[columns_name]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel importance\n",
      "channel num :1 ~ 32\n",
      "['Ch2', 0.038242839513376176]\n",
      "['Ch4', 0.03819682592920495]\n",
      "['Ch10', 0.037350127066646914]\n",
      "['Ch3', 0.03677712435293869]\n",
      "['Ch26', 0.03611987385231999]\n",
      "['Ch27', 0.03609429042794179]\n",
      "['Ch6', 0.035408378887680475]\n",
      "['Ch1', 0.03489035224847585]\n",
      "['Ch28', 0.034257896357009744]\n",
      "['Ch29', 0.0341338445914672]\n",
      "['Ch5', 0.03390268526106585]\n",
      "['Ch14', 0.03359165032059278]\n",
      "['Ch17', 0.033384363130639354]\n",
      "['Ch30', 0.033235373273846625]\n",
      "['Ch20', 0.03290512798782788]\n",
      "['Ch13', 0.032598207081357175]\n",
      "['Ch9', 0.032596507247777254]\n",
      "['Ch21', 0.03176182998008998]\n",
      "['Ch32', 0.030993883241998317]\n",
      "['Ch8', 0.030664719363380968]\n",
      "['Ch11', 0.030410779263039235]\n",
      "['Ch24', 0.030241990858975252]\n",
      "['Ch22', 0.029918302733440122]\n",
      "['Ch25', 0.029793875283570838]\n",
      "['Ch15', 0.029575586925487354]\n",
      "['Ch23', 0.029135865956550815]\n",
      "['Ch31', 0.029125918028880524]\n",
      "['Ch7', 0.02753411947861204]\n",
      "['Ch16', 0.026187644509038044]\n",
      "['Ch12', 0.025985618299923928]\n",
      "['Ch19', 0.02498439854684391]\n",
      "['Ch18', 0.0]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "selecting feature number :  160\n"
     ]
    }
   ],
   "source": [
    "data = channel_select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACh1</th>\n",
       "      <th>ACh10</th>\n",
       "      <th>ACh11</th>\n",
       "      <th>ACh12</th>\n",
       "      <th>ACh13</th>\n",
       "      <th>ACh14</th>\n",
       "      <th>ACh15</th>\n",
       "      <th>ACh16</th>\n",
       "      <th>ACh17</th>\n",
       "      <th>ACh18</th>\n",
       "      <th>...</th>\n",
       "      <th>TCh3</th>\n",
       "      <th>TCh30</th>\n",
       "      <th>TCh31</th>\n",
       "      <th>TCh32</th>\n",
       "      <th>TCh4</th>\n",
       "      <th>TCh5</th>\n",
       "      <th>TCh6</th>\n",
       "      <th>TCh7</th>\n",
       "      <th>TCh8</th>\n",
       "      <th>TCh9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.512153</td>\n",
       "      <td>69.925212</td>\n",
       "      <td>11.263455</td>\n",
       "      <td>13.204760</td>\n",
       "      <td>21.564257</td>\n",
       "      <td>40.455822</td>\n",
       "      <td>61.780233</td>\n",
       "      <td>63.703514</td>\n",
       "      <td>5.997749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.673796</td>\n",
       "      <td>11.507832</td>\n",
       "      <td>11.162954</td>\n",
       "      <td>9.491918</td>\n",
       "      <td>3.598896</td>\n",
       "      <td>5.941709</td>\n",
       "      <td>1.656927</td>\n",
       "      <td>9.760826</td>\n",
       "      <td>8.661677</td>\n",
       "      <td>7.235869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.539769</td>\n",
       "      <td>24.128985</td>\n",
       "      <td>5.103897</td>\n",
       "      <td>4.117744</td>\n",
       "      <td>11.495993</td>\n",
       "      <td>17.199812</td>\n",
       "      <td>14.364287</td>\n",
       "      <td>15.798085</td>\n",
       "      <td>5.016286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.966718</td>\n",
       "      <td>15.457455</td>\n",
       "      <td>22.764836</td>\n",
       "      <td>22.393518</td>\n",
       "      <td>13.196881</td>\n",
       "      <td>17.423661</td>\n",
       "      <td>13.353375</td>\n",
       "      <td>22.059684</td>\n",
       "      <td>19.089995</td>\n",
       "      <td>14.375457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.876811</td>\n",
       "      <td>49.574373</td>\n",
       "      <td>4.760022</td>\n",
       "      <td>8.141746</td>\n",
       "      <td>17.605909</td>\n",
       "      <td>27.498355</td>\n",
       "      <td>30.822483</td>\n",
       "      <td>33.346680</td>\n",
       "      <td>9.764571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.341504</td>\n",
       "      <td>11.118133</td>\n",
       "      <td>11.282202</td>\n",
       "      <td>10.760432</td>\n",
       "      <td>5.847675</td>\n",
       "      <td>13.561016</td>\n",
       "      <td>13.076631</td>\n",
       "      <td>14.896952</td>\n",
       "      <td>5.983786</td>\n",
       "      <td>7.681887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.224107</td>\n",
       "      <td>41.379676</td>\n",
       "      <td>10.889194</td>\n",
       "      <td>13.341544</td>\n",
       "      <td>25.956096</td>\n",
       "      <td>31.839421</td>\n",
       "      <td>40.649491</td>\n",
       "      <td>41.080129</td>\n",
       "      <td>12.167993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.495164</td>\n",
       "      <td>12.461344</td>\n",
       "      <td>12.748985</td>\n",
       "      <td>11.845096</td>\n",
       "      <td>4.677333</td>\n",
       "      <td>11.372016</td>\n",
       "      <td>7.316882</td>\n",
       "      <td>12.464392</td>\n",
       "      <td>10.458767</td>\n",
       "      <td>10.555316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.441049</td>\n",
       "      <td>32.524267</td>\n",
       "      <td>15.373357</td>\n",
       "      <td>12.630065</td>\n",
       "      <td>13.485333</td>\n",
       "      <td>24.469171</td>\n",
       "      <td>27.148828</td>\n",
       "      <td>39.845233</td>\n",
       "      <td>16.420239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.863384</td>\n",
       "      <td>17.095190</td>\n",
       "      <td>13.764769</td>\n",
       "      <td>13.443134</td>\n",
       "      <td>15.429647</td>\n",
       "      <td>7.212496</td>\n",
       "      <td>13.094720</td>\n",
       "      <td>18.202155</td>\n",
       "      <td>14.269946</td>\n",
       "      <td>14.342443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>9.377716</td>\n",
       "      <td>27.170256</td>\n",
       "      <td>7.786197</td>\n",
       "      <td>7.483846</td>\n",
       "      <td>8.699358</td>\n",
       "      <td>9.498228</td>\n",
       "      <td>19.238846</td>\n",
       "      <td>21.895583</td>\n",
       "      <td>9.291614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.636472</td>\n",
       "      <td>16.539841</td>\n",
       "      <td>15.194092</td>\n",
       "      <td>14.108681</td>\n",
       "      <td>11.146622</td>\n",
       "      <td>11.763126</td>\n",
       "      <td>10.808589</td>\n",
       "      <td>17.442276</td>\n",
       "      <td>15.556296</td>\n",
       "      <td>11.719461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>11.906533</td>\n",
       "      <td>26.798845</td>\n",
       "      <td>8.607284</td>\n",
       "      <td>8.793221</td>\n",
       "      <td>14.757784</td>\n",
       "      <td>17.676136</td>\n",
       "      <td>29.588759</td>\n",
       "      <td>26.990570</td>\n",
       "      <td>10.649820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.628756</td>\n",
       "      <td>16.142647</td>\n",
       "      <td>14.712165</td>\n",
       "      <td>14.551317</td>\n",
       "      <td>14.200540</td>\n",
       "      <td>14.729774</td>\n",
       "      <td>15.432356</td>\n",
       "      <td>19.029062</td>\n",
       "      <td>17.546902</td>\n",
       "      <td>15.830547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>10.335814</td>\n",
       "      <td>28.485295</td>\n",
       "      <td>18.912526</td>\n",
       "      <td>18.150611</td>\n",
       "      <td>30.372339</td>\n",
       "      <td>37.062017</td>\n",
       "      <td>34.595179</td>\n",
       "      <td>38.866391</td>\n",
       "      <td>21.816493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.128340</td>\n",
       "      <td>25.657373</td>\n",
       "      <td>24.098649</td>\n",
       "      <td>19.401579</td>\n",
       "      <td>20.523636</td>\n",
       "      <td>32.627739</td>\n",
       "      <td>24.731760</td>\n",
       "      <td>30.105868</td>\n",
       "      <td>24.842073</td>\n",
       "      <td>23.474267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>14.781336</td>\n",
       "      <td>30.794355</td>\n",
       "      <td>9.252369</td>\n",
       "      <td>9.115270</td>\n",
       "      <td>15.796576</td>\n",
       "      <td>11.005532</td>\n",
       "      <td>32.923175</td>\n",
       "      <td>29.777934</td>\n",
       "      <td>13.468513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.261000</td>\n",
       "      <td>22.937862</td>\n",
       "      <td>23.429094</td>\n",
       "      <td>12.989213</td>\n",
       "      <td>8.635734</td>\n",
       "      <td>21.508771</td>\n",
       "      <td>14.345015</td>\n",
       "      <td>26.358745</td>\n",
       "      <td>22.176200</td>\n",
       "      <td>18.592818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.816538</td>\n",
       "      <td>4.903818</td>\n",
       "      <td>1.521836</td>\n",
       "      <td>1.898748</td>\n",
       "      <td>3.094132</td>\n",
       "      <td>13.194965</td>\n",
       "      <td>10.555151</td>\n",
       "      <td>6.283506</td>\n",
       "      <td>0.822076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236288</td>\n",
       "      <td>2.804871</td>\n",
       "      <td>5.997765</td>\n",
       "      <td>6.470478</td>\n",
       "      <td>0.311200</td>\n",
       "      <td>0.272222</td>\n",
       "      <td>0.569408</td>\n",
       "      <td>2.577463</td>\n",
       "      <td>1.532817</td>\n",
       "      <td>2.856662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ACh1      ACh10      ACh11      ACh12      ACh13      ACh14  \\\n",
       "0     4.512153  69.925212  11.263455  13.204760  21.564257  40.455822   \n",
       "1     4.539769  24.128985   5.103897   4.117744  11.495993  17.199812   \n",
       "2     9.876811  49.574373   4.760022   8.141746  17.605909  27.498355   \n",
       "3     4.224107  41.379676  10.889194  13.341544  25.956096  31.839421   \n",
       "4    18.441049  32.524267  15.373357  12.630065  13.485333  24.469171   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "235   9.377716  27.170256   7.786197   7.483846   8.699358   9.498228   \n",
       "236  11.906533  26.798845   8.607284   8.793221  14.757784  17.676136   \n",
       "237  10.335814  28.485295  18.912526  18.150611  30.372339  37.062017   \n",
       "238  14.781336  30.794355   9.252369   9.115270  15.796576  11.005532   \n",
       "239   0.816538   4.903818   1.521836   1.898748   3.094132  13.194965   \n",
       "\n",
       "         ACh15      ACh16      ACh17  ACh18  ...       TCh3      TCh30  \\\n",
       "0    61.780233  63.703514   5.997749    0.0  ...   5.673796  11.507832   \n",
       "1    14.364287  15.798085   5.016286    0.0  ...  16.966718  15.457455   \n",
       "2    30.822483  33.346680   9.764571    0.0  ...   5.341504  11.118133   \n",
       "3    40.649491  41.080129  12.167993    0.0  ...   5.495164  12.461344   \n",
       "4    27.148828  39.845233  16.420239    0.0  ...  11.863384  17.095190   \n",
       "..         ...        ...        ...    ...  ...        ...        ...   \n",
       "235  19.238846  21.895583   9.291614    0.0  ...  14.636472  16.539841   \n",
       "236  29.588759  26.990570  10.649820    0.0  ...  15.628756  16.142647   \n",
       "237  34.595179  38.866391  21.816493    0.0  ...  23.128340  25.657373   \n",
       "238  32.923175  29.777934  13.468513    0.0  ...  10.261000  22.937862   \n",
       "239  10.555151   6.283506   0.822076    0.0  ...   0.236288   2.804871   \n",
       "\n",
       "         TCh31      TCh32       TCh4       TCh5       TCh6       TCh7  \\\n",
       "0    11.162954   9.491918   3.598896   5.941709   1.656927   9.760826   \n",
       "1    22.764836  22.393518  13.196881  17.423661  13.353375  22.059684   \n",
       "2    11.282202  10.760432   5.847675  13.561016  13.076631  14.896952   \n",
       "3    12.748985  11.845096   4.677333  11.372016   7.316882  12.464392   \n",
       "4    13.764769  13.443134  15.429647   7.212496  13.094720  18.202155   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "235  15.194092  14.108681  11.146622  11.763126  10.808589  17.442276   \n",
       "236  14.712165  14.551317  14.200540  14.729774  15.432356  19.029062   \n",
       "237  24.098649  19.401579  20.523636  32.627739  24.731760  30.105868   \n",
       "238  23.429094  12.989213   8.635734  21.508771  14.345015  26.358745   \n",
       "239   5.997765   6.470478   0.311200   0.272222   0.569408   2.577463   \n",
       "\n",
       "          TCh8       TCh9  \n",
       "0     8.661677   7.235869  \n",
       "1    19.089995  14.375457  \n",
       "2     5.983786   7.681887  \n",
       "3    10.458767  10.555316  \n",
       "4    14.269946  14.342443  \n",
       "..         ...        ...  \n",
       "235  15.556296  11.719461  \n",
       "236  17.546902  15.830547  \n",
       "237  24.842073  23.474267  \n",
       "238  22.176200  18.592818  \n",
       "239   1.532817   2.856662  \n",
       "\n",
       "[240 rows x 160 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.array(data.iloc[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2= np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 160)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA 적용후 k-fold validation으로 RandomForest진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6666666666666666, 0.875, 0.875, 0.7083333333333334, 0.9166666666666666, 0.875, 0.7083333333333334, 0.9166666666666666, 0.875, 0.9166666666666666]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "skf.get_n_splits(X2,Y2)\n",
    "all_scores = []\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100)\n",
    "lda = LinearDiscriminantAnalysis(n_components=None)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=11)\n",
    "lda.fit(X2,Y2)\n",
    "\n",
    "X_reduced_lda = lda.transform(X2)\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X_reduced_lda,Y2):\n",
    "    rnd_clf.fit(X_reduced_lda[train_index], Y2[train_index])\n",
    "    val_mae = rnd_clf.score(X_reduced_lda[test_index],Y2[test_index])\n",
    "    all_scores.append(val_mae)\n",
    "    \n",
    "print(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.33333333333333 %\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(all_scores)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph ():\n",
    "    result = []\n",
    "    feature_num = [] \n",
    "    for i in range(1,33):\n",
    "        select_channel=sorting_important[0:i]\n",
    "        columns_name = []\n",
    "        for j in range(len(select_channel)):\n",
    "            columns_name.append(\"A\"+select_channel[j][0])\n",
    "            columns_name.append(\"B\"+select_channel[j][0])\n",
    "            columns_name.append(\"D\"+select_channel[j][0])\n",
    "            columns_name.append(\"G\"+select_channel[j][0])\n",
    "            columns_name.append(\"T\"+select_channel[j][0])\n",
    "        columns_name = sorted(columns_name)\n",
    "        df = eeg_data[columns_name]\n",
    "        X2 = np.array(df.iloc[:])\n",
    "        Y2= np.array(Y)\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "        skf.get_n_splits(X2,Y2)\n",
    "        all_scores = []\n",
    "        rnd_clf = RandomForestClassifier(n_estimators=100)\n",
    "        lda = LinearDiscriminantAnalysis(n_components=11)\n",
    "        lda.fit(X2,Y2)\n",
    "        X_reduced_lda = lda.transform(X2)\n",
    "        for train_index, test_index in skf.split(X_reduced_lda,Y2):\n",
    "            rnd_clf.fit(X_reduced_lda[train_index], Y2[train_index])\n",
    "            val_mae = rnd_clf.score(X_reduced_lda[test_index],Y2[test_index])\n",
    "            all_scores.append(val_mae)\n",
    "        result.append(np.mean(all_scores)*100)\n",
    "    for k in range (5,165,5):\n",
    "        feature_num.append(k)\n",
    "        \n",
    "    plt.figure(figsize=(11,4))\n",
    "    plt.title(\"LDA k-fold validation RandomForest \", fontsize=14)\n",
    "    plt.xlabel(\"Top_feature_number\", fontsize=14)\n",
    "    plt.ylabel(\"Accuracy\", fontsize=14)\n",
    "    plt.xlim(0,165)\n",
    "    plt.ylim(0,100)\n",
    "    plt.plot(feature_num,result)\n",
    "    plt.grid(which='both')\n",
    "    plt.show()    \n",
    "    return list(zip(feature_num, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqAAAAEbCAYAAAAF2TbuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd5wV5dn/8c+1na2U3aWXpTcBqSpEF4wda4xBjb3ERI2/FKNGU54napInpphqNGJvaGyxGxURFZCidBDZhaXuUrex9dy/P2bAw7oLBzhly/f9ep3XOVPOzDXXDrsX98zctznnEBERERGJlrhYByAiIiIibYsKUBERERGJKhWgIiIiIhJVKkBFREREJKpUgIqIiIhIVKkAFREREZGoUgEqIk0yM2dm5x/id7qY2VtmVmFmIfXzZmaXm1n5Qdb5sZkVHkosh8rM+vjHPLax6Sa+M9Zfp084991amVm2f5z5sY5FRGJHBahIM2VmD5vZKwdYXuj/IXdmVmVmRWb2gpmdeYDv/NnM6s3smshEDcCPgW7AKKBrBPcTDUV4x/BpODdqZjPN7K/R2Fcj+84POm+cmW03s3fNbGIk9xsLDY5z7yui+Q0xrkIz+3Gs4xCJJRWgIi3b/+IVLQOBaUAh8IKZ/aXhimaWDFwM/Aa4OoIx9QcWOOc+d85tieB+Is45V++c2+Kcq2tN+/INwzt38oES4FUzy43SvqPpGrzj3Ps68XA3ZGZJ4QpKpK1TASrSspX5Rct659yHzrkfAN8DbjCzyQ3WPQ+vQL0LGGJmww91Z2Z2i5ltM7MJTSwvBM4GLvVbmx725/fyW2fL/NfzZtbjIPv6iZltMbNyM3sUSD/I+h+b2e8bzMs0sz1mdq4//W0z+8SPodjMnjWz7gfY5lcui5vZqWa20m91/gCv+A/+Ticze8rMNvj7XmZmVwQtfxg4Abg+qFWuTxP7Ot7M5vr72mpmfwwugvyW1L+b2d3+z6XYzO4xs1B+txf7584S4E4gC9j3czWzcf6tFNvMrNTMZpvZsQ2O1ZnZtX4eK8xsrZl9u8E648xsgX8Mi4L3cYjH+Q8z+72Z7TCzEjO7ycySzexvZrbLzNab2SWNHOcu/zj3vrYHbfcoM/uv/3PaYd5Vh6zgn5WZveKf9xuADf78JDP7rf8zrvDPqVOCvpdo3tWGTWZWbd7Vid/sPRagN/C7vT//EH5WIq2OClCR1udBYCfwjQbzrwYed85VAs9zCK2g5rkHuBE4wTk3t4lVxwH/BWbgtTbdZGYGvAh0BqYAk/Eu0b/oL2tsfxfgFUW/AEYDq4AfHiTMx4FpDYqvbwB7gFf96SR/myOBqUA28NRBthscV0//WN7Gu8XgL8D/NVgtBVjob38YcC/wTzPb2/J2E/Ax8BBftsoVNbKv7sDrwCLgaOAq4ELg1w1WvRioA44DbgD+H/CtQzimVGBvgVwbtCgDeAz4GjAe79aA18wsu8Emfg68hJfTZ4DpZtbb33YaXu7XAmOBW4F7juA4y/AK2N8Af8L7Waz2t/0I8C8z63YIx/0GUO4f37l4OZzeYNUTgBHAqXzZevqQP/8i4Ch/3/8xs5H+8u/725sGDMD7eazyl52HV8juvXrR0m9TETk8zjm99NKrGb6Ah4FXDrC8EPhxE8vmAK8FTfcFaoAu/vQUYBuQfJAYHN4fz4fw/tD3CSHuV4CHg6ZPAuqDv+vHEwC+7k9fDpQHLf8IeKDBdv8LFB5gv538YzyxwXf+eYDvDPaPsYc/3cefHtvE9N1+HixoG3f46zSZG+Bp4F9B0zOBvzZYp+G+7gLWAHFB61wOVAOpQdv5uMF23g7eVyOx5Pv7KfdfAX/6EyDxAN8zYDPw7Qbnx6+DphOAyr3rANcCu4D0oHW+7X8v/3CP04+lBHg5aF6i//M/v0F8e4KOtRy42F92DbAbyGgkN/2D/g2WEPTvBOjn56xXg/y8CPzd//xn4J3g8yTUf7t66dVWXmoBFWmdDO8P6V5XAu+4L+/JnIlXKJwTwrbuwfvDPMk5V7hvB2Y/9S+P7331auL7Q4BNwd91zq0FNgFDD/CdjxvMazi9H+ddWn0Tr6UMM+uK19r6eFDMo83sJTNbZ2ZlwHx/UVOxNxbXHOdccG73i8vM4s3sdjNbbN4DPuV4rV6h7iN4Xx875wJB82bjteL2D5q3uMH3NgGh3Ms5Ga91+UKgALjMObevBdTMcs3sn2a22sx247U+5jZyHPv277z7V0uC9j8EWOycC+7hoOHP8ZCP089/MbAkaF4tXst/w2O/Ga+1eu/r5QaxlQWt+xFecRl8Xi51zlUHTY/G+/e1PPj8B87AK07BK1xHAav9WwTOCPG2CJE2IyHWAYhIeJlZPN59ifOCpi8HuplZ8AMucXiX4Z85yCbfxitSTsf7w7rXfXiX2vfa1FRI7F8MBwv3/W+PA/eb2ffwYi7CK2b2Xg5+E69V9BK8AiYb+ACv2AlFo7cMNPBj4Ed4l9qX4LW63U1oRWHDfYWSt9pGloVS7BQ457bhFUkpwPNmNjKo2HoE77aJH+C12FXjteo1zNWB9h9Kvo7kOEM59i3OuTVHsN+KBsvi/OXjGtn/HgDn3ELzuuU6Fe9qwyPAZ2Z2UoNCW6TN0v/IRFqfq4H2wHP+9Kl4l6fHsn9L0FTgRDt4/5WvAd8E/mFml+2d6Zzb4ZxbE/Rq6unt5UD34P2YWV+8+0CXN/GdFcAxDeY1nG7MS/77VLyW0CeCWisH4xWcP3XOzXLOreTQi8LlwIQG9642jGsS8B/n3GPOuU+BL2jwoBLepeL4EPZ1bIOWs0n+d784xLgP5jG8S9jXN9jXX5xzrzrnluG1gB7q/YrLgaP84n+vhvmK5nE23O9IM8sImncc3t/FFQf43iK84rVLg/N/jXNu496VnHNlzrlnnXPfxWsdncKXLbqh/PxFWjUVoCLNW6aZjWrw6hO0PMO8jt97mtlxZvZH4G949xe+769zNfC6c26hc25p0Os1vAcjrjxYEM65V/CK0PvM7NJDPIb/Ap8BT5jZGPOe8n4C70Gdd5v4zr3AZWZ2jZkNMLPbaOTp6UbirMJ7wOoOvEuljwctXo/XineDmfU1szOAXx3isdyHd6/mn8xskHmd9F/XYJ3VeIX9JDMbDPwVyGuwTiEw3rwn37ObuDz7d7wi/e9mNsSP9zd4P9vKQ4z7gPxWuT8BtwYVi6uBb5vZUDMbh3cfa80hbvpJvAekppvZMDM7Cbi9wTpRO84GnsBr3XzUfxr+eOCfwPNNtJgC4Jxb7X/3YTM73z+Xxpo3UMJ5AGb2QzO70D+e/ngPK5XiP0WP9/P/mpl1b+ShLpE2QQWoSPP2NbwWl+BX8FPEP8d7MGQN3uXwPOA859yNAGbWGa818Dka9yxwRSj3p/lF6AV4T3SHXIT6LZDn4N0bOBN4D9gCnNPgXsrg7zwD/BLvAZVFeE8a/yHEXT6G90T2QufcvpYs51wJcJkfy3K8p+EP9mR9w7jW493PeSpeUf0DvCe7g92Jd/vD68AsvCLniQbr3INXzC3Hy8tX7g/1W9NOw3sy/FO8p7OfAn56KDEfgul4t2Xd5E9fidf11QK84nM6XuEUMv/ez6l4T4IvxDvuWxqsE+3j3LvfSuAUIBPv5/US3v2pB/0PGV6vAQ/h9YCwEu/Bu+OBdf7yMrx7T+fhHfco4LSggvrnQE+8Ft6SMByOSItjTfz+FxERERGJCLWAioiIiEhURa0ANbPp5o3SsTRoXkcze9vMPvffO/jzzbxRJNb4XZmMjlacIiIiIhJZ0WwBfRjvvqlgt+L1TTgAr3uPvfdSnYZ3z9AAvI6M/xGlGEVEREQkwqJWgDrnZgE7Gsw+G69/NPz3c4LmP+o8c4D2fqfSIiIiItLCxboj+s7Ouc0AzrnNZra3T77u7D828gZ/3uaGGzCza/FaSUlJSRnTq9ehDjbS9gQCAeLidPtvKJSr0ChPoVOuQqM8hUZ5Cp1yFZpw5mn16tXbnHM5jS2LdQHalMZGz2iqu5b7gfsBBg0a5FatWhXJuFqFmTNnkp+fH+swWgTlKjTKU+iUq9AoT6FRnkKnXIUmnHkys3VNLYv1fwW27r207r8X+/M34PWRtlcPmh7mT0RERERakFgXoC/jdQyN//5S0PxL/afhjwF2771ULyIiIiItW9QuwZvZU0A+kG1mG/BGIfkNMMPMrsIbJu+b/uqvAafjje5SiTfqhIiIiIi0AlErQJ1zFzax6MRG1nXA9ZGNSERERERiIdaX4EVERESkjVEBKiIiIiJRpQJURERERKJKBaiIiIiIRJUKUBERERGJKhWgIiIiIhJVKkBFREREJKpUgIqIiIhIVKkAFREREZGoUgEqIiIiIlGlAlREREREokoFqIiIiIhElQpQEREREYkqFaAiIiIiElUqQEVEREQkqlSAioiIiEhUqQAVERERkahSASoiIiIiUaUCVERERESiSgWoiIiIiESVClARERERiSoVoCIiIiISVSpARURERCSqVICKiIiISFSpABURERGRqFIBKiIiIiJRpQJURERERKJKBaiIiIhIlNXVB9hTUx/rMPZTH3AUVwaisq+EqOxFRERERNheXs2Tc9fz6Jx1bCuvpm92GsO6ZTG8eybDu2UxrFsWWamJEY+jpi7A58VlLNtYytJNu1m6cTcrNpdRU1fPWSfVk5IYH9H9qwAVERERibBVW8p46MMCXli0keq6ACcMzGFkz/as2FzK/MIdvPzZpn3r9uzYjuHdshjePYth3TIZ1i2LnIzkw953VW09KzaXsnRTKcs37WbpxlJWbSmjpt5r7UxPTmBot0wuHN+L+NKNR3ysoVABKiIiIhIBgYBj5upips8uZPaabaQkxvGNMT244rg+DOicsd+628urWbbJa43c2yr5+tIt+5Z3zkz2Wki7ZzG8WybDu2fRNSsFM9tvO+XVdSzfVMrSjbv3bWtNSTn1AQdA+9REhnfL4opJffYVub07phIX521n5sziiLd+ggpQERERkbCqqK7j+YUbeOjDQtZuq6BLZgo/OXUQF47rRYe0pEa/0yk9meMH5nD8wJx980qravcVk8v89/dWFePXknRMS2JYt0wGdc5gS2kVyzaVUrCtYt/3czOSGd49i1OGdfYK1+5ZdGukaI0FFaAiIiIiYbBx1x4e/aiQp+atp7SqjpE9srh32ihOP6orifGH/tx3Zkoix/TtxDF9O+2bV1lTx4rNZSwLail95ONCcjNSGN49k/OO7r7v0n1uZkoYjy68VICKiIiIHCbnHAvX72T67ELeWLYF5xynDe/KlZPyGN2rfdhbG1OTEhjTuwNjenfYL4bm0Kp5KFSAioiIiByi2voAry3ZzPQPC/msaBcZKQlcPSmPS47tTY8OqVGNpaUVn9BMClAz+wFwNeCAJcAVQFfgaaAjsBC4xDlXE7MgRUREpM3bWVHDk/PW89jH69hSWkVedhr/e/YwvjG6B2nJzaKsahFinikz6w58HxjqnNtjZjOAacDpwB+dc0+b2X3AVcA/YhiqiIiItEEbd+3hvZXFvLeymNlrtlFdF2BS/2zuPm84+QNz9z1BLqGLeQHqSwDamVktkApsBqYAF/nLHwF+iQpQERERibC6+gAL1+/iXb/oXLW1DPD657xwfC+mje/J4C6ZMY6yZTPnXKxjwMxuAu4C9gBvATcBc5xz/f3lPYHXnXPDG/nutcC1ADk5OWNmzJgRtbhbqvLyctLT02MdRougXIVGeQqdchUa5Sk0ylPoDpar0hrHkpI6PiupZ+m2eirrIN5gYIc4RuQkMDInnq5p1iLvtzwU4TynJk+evMA5N7axZTFvATWzDsDZQB6wC3gWOK2RVRutlJ1z9wP3AwwaNMjl5+dHJtBWZObMmShPoVGuQqM8hU65Co3yFBrlKXQNc+WcY9mmUq+Vc1UxnxbtwjnITk/m9JFdmTI4l0kDsslMifywmM1JtM6pmBegwNeBAudcCYCZPQ8cB7Q3swTnXB3QA9h0gG2IiIiIHFB5dR2zP9/m3c+5qpjismoARvbI4qYTBzBlcC7Du2Xpns4oaA4F6HrgGDNLxbsEfyIwH3gPOB/vSfjLgJdiFqGIiIi0CPUBx/aKaopLqykpq6a4rIotu6t5c9EePn/7LWrrHRnJCRw/MIfJg3M5YWDOEY2zLocn5gWoc26umT2H19VSHbAI75L6q8DTZnanP+/B2EUpIiIisVRTF6CkvJri0iqKy6opLqumJOhzcVkVxaXVbCuv3jdUZbBuacYVE/OYPCiXsX06HNbIRBI+MS9AAZxzvwB+0WD2WmB8DMIRERGRGCqvrmPGJ0XeZfJSr7jcWVn7lfXMoFNaMrkZyeRmJjO0aya5GSnkZnrzcjJS/Pdk5nz4Afn5Q2JwNNKYZlGAioiIiBTtqOThjwqZ8UkRZdV1DO6SQe9OqYzL6+AVln6hufdzx7QkEtSS2SKpABUREZGYcc4xr2AH0z8s4O3lW4kz44wRXbliYh6jeraPdXgSISpARUREJOqq6+p55bPNTP+wgGWbSmmfmsh38/txyTF96JKVEuvwJMJUgIqIiEjUbCuv5sm563lszjpKyqrpn5vO3ecexblHd6ddUnysw5MoUQEqIiIiEbdySynTZxfw4qebqKkLkD8ohysn5vG1AdmtfnQh+SoVoCIiIhIRgYDjvVXFTP+wgA/XbCclMY5vjunBFRP70D83I9bhSQypABUREZGwqqiu47kFG3j4o0IKtlXQJTOFW04dzIXje9I+NSnW4UkzoAJUREREjlhpVS0L1u1k1uoSnluwgbKqOkb2bM+fLzya04Z3Ucfvsh8VoCIiInLIdlTU8EnhDuau3cG8wu0s31RKwEFCnHHK8C5cOTGPMb07xDpMaaZUgIqIiMhBFZdWMbdgB/MKdjC3YDurt5YDkJwQx9G92nPDlAFMyOvI0b3ak5qk8kIOTGeIiIhIC1NZU8eTc9fz5Md7eGDNnH0jA+X4r+DhKNOTEw7rKfMNOyu9YnPtDuYV7qBgWwUAqUnxjOndgbNHdWd8XkdG9MgiOUHdJ8mhUQEqIiLSQpRX1/Hox4U8+EEB2ytqyMuKY09NPZ8U7qC4rJqausBXvtMuMX5fMZqbkeIVqJnJ5KQnk5vpD2+ZkczuPbXM29fCuYONu/YAkJmSwPi8jlw4vicT8joxrFumhr+UI6YCVEREpJnbXVnLwx8VMv3DAnbvqeWEgTncOKU/5YWLyc+fCHhDWpbuqaO4rIrismrvvbTa/1xNcWkVKzaX8v7qasqr65rcV3Z6EuPzOnLN1/IYn9eJwV0yiItTP50SXipARUREmqkdFTU8OHstj360jrLqOk4a2pkbJvdnpD9G+szCL9c1M7JSE8lKTWRA5wP3sVlZU7evOC3xi9XkhHjG53WkX06aOoaXiFMBKiIi0swUl1XxwKy1PD5nPVV19Zw+vCvXT+7P0G6ZYdl+alICfbIT6JOdFpbtiRwqFaAiIiLNxKZde7h/1lqemree2voAZ4/qzvfy+x20RVOkpVEBKiIiEmNFOyr5+8wveG5BEc7BeaO78738/mqhlFZLBaiIiEiMrC0p5+8zv+CFRRuJN+Nb43ryneP70bNjaqxDE4koFaAiIiJRtmpLGX97bw2vLN5EYnwclx7bm+8c348uWSmxDk0kKlSAioiIREFFdR3/XbGVlz/dxDsri0lNiuea4/ty9aS+5GQkxzo8kahSASoiIhIhVbX1vLeymFcWb+adlVupqg3QOTOZG6f058qJeXRIS4p1iCIxoQJUREQkjKrr6vlg9TZeWbyJt5dvpaKmnuz0JL45pidTR3RlXJ+O6thd2jwVoCIiIkeotj7AR19s5z+fbeLNZVsoq6ojq10iZ47sxtQR3Timb0cNXykSRAWoiIjIYagPOOau3c5/Fm/mjaWb2VlZS0ZyAicN68yZI7oxsX82SQkqOkUaowJUREQkRIGAY8H6nbzy2SZeW7qFkrJq2iXG8/WhnZk6oisnDMwhJTE+1mGKNHsqQEVERJqwp6aewu0VFG6rYMG6nby6ZDObd1eRlBDHlEG5nDmyG1MG59IuSUWnyKFQASoiIm1aTV2A9TsqKdxWQcG2Cgq2V1BQUkHh9go2767at15ivHH8gBx+cuogvj6kMxkpiTGMWqRlUwEqIiKtXn3AsXHnHr+4LKdwe6VXbG6rYMPOSgLuy3XbpyaSl53GsX070Sc7jbygV1qy/myKhIP+JYmISKvjnOOjL7bz5Lz1rNxcStGOPdTUB/YtT0uKJy8njRE9sjhnVDf6ZKd5xWanNPXNKRIFKkBFRKTVqKqt56VPNzJ9diGrtpbRKS2JsX06cNLQLuRlp5KXnU6f7FRy0pMxU1+cIrESUgFqZn8C/uWcWxrheERERA5ZcWkVj81ZxxNz17OjooYhXTP53fkjOGtUN5IT9ICQSHMTagvoOOBGM1sA/At42jlXGrmwREREDm7pxt1Mn13AfxZvoi7g+PqQzlw5MY9j+nZUC6dIMxZSAeqcm2hmg4ArgV8AfzCz54EHnXPvRzJAERGRYPUBx9vLtzB9diHzCneQlhTPxRN6c8XEPvTulBbr8EQkBCHfA+qcWwXcYma3AafjFaNvmdl64EHgfufcjsiEKSIibV1pVS0zPini4Y8K2bBzDz06tOOOM4ZwwbieZKpLJJEW5XAeQkoEMoEsIB5YD1wC3GFm1zrnnjzUDZpZe7xL+8MBh1fcrgKeAfoAhcAFzrmdhxGviIi0YIXbKnj4o0KenV9ERU094/t05I4zhnDS0C7Ex+kyu0hLFHIBamZj8QrDaUAl8AhwtXOuwF9+E/BH4JALUOBe4A3n3PlmlgSkAj8F3nHO/cbMbgVuBW45jG2LiEiElVXV8uKijQCkJiWQlpxAWnK8957kf/bnhzI+uteN0jamzy7knZVbSYgzzhzRjSsm5nFUj6xIH46IRFioT8EvAQYBbwKXA6865+obrPYkXgF6SMwsEzje3y7OuRqgxszOBvL91R4BZqICVESk2Vm9tYzrHlvA2m0VIa2fGG+kJiWQnpxAalL8l8VqUOH6/rIqit6cS8e0JG6Y3J9LjulNbmZKhI9ERKLFnHMHX8nsZ8B059zGsAdgNgq4H1gOjAQWADcBG51z7YPW2+mc69DI968FrgXIyckZM2PGjHCH2OqUl5eTnp4e6zBaBOUqNMpT6FpbruZsqmP6smraJRjXjUimW3oc1fWOPXWO6nqoqnNU+e/VdbCn3nuvqndU+e9fTnvrVtc5MpMcJ+clc2zXBJLidZm9Ka3tfIok5So04czT5MmTFzjnxja2LNQCNAmIc85VNZifAgT8VsvD4l/anwNMdM7NNbN7gVLgxlAK0GCDBg1yq1atOtxQ2oyZM2eSn58f6zBaBOUqNMpT6FpLrmrqAtz92goe/qiQ8X068teLjg5rC2VryVOkKU+hU65CE848mVmTBejBb8TxPAt8r5H51wFH2uS4AdjgnJvrTz8HjAa2mllXAP+9+Aj3IyIiYbC1tIqLHpjDwx8VctWkPJ64ZoIuj4vIIQm1AJ0IvNXI/LeB444kAOfcFqDI72cU4ES8y/EvA5f58y4DXjqS/YiIyJGbs3Y7Z/x5Nss3l/LXi47mZ1OHkhgf6p8SERFPqE/BpwJ1jcwPABlhiONG4An/Uv9a4Aq84niGmV2F19XTN8OwHxEROQzOOf71QQG/eWMlvTul8tQ1ExjQORy//kWkLQq1AF0MXIg3ClKwi4AjHh/eOfcp0Ng9Aice6bZFROTIlFfX8ZPnPuO1JVs4bXgX/u/8EWSo43cROQKhFqC/Al40s/7Au/68E/FaJc+NRGAiIhJ7a4rL+M5jCyjcXsntpw/h6q/laYx1ETlioY4F/6qZnQncAfzZn70IOMs593qkghMRkdh5ZfEmfvLcYlKT4nni6gkc07dTrEMSkVbiUMaCfwN4I4KxiIhIM1BbH+A3r6/kwdkFjOndgb9dNJouWXrKXUTC53DGghcRkVaquKyKG55YxLzCHVx+XB9+evqQkIbOFBE5FKEOxZkE3I73IFIvYL+7z51z8eEPTUREoumTwh1874mFlFfVce+0UZw9qnusQxKRVirU/9b+Cq8vzt/jdb10M/A3YDuNd1AvIiIthHOO6bMLuPD+OaQnJ/Di9RNVfIpIRIV6Cf4C4Drn3Btmdg/wknPuCzNbAZwE/DNiEYqIyD6rt5YxfXYBc9ZuJyUxnvTkBFKTE0hPjic1KcGbToonLTmBtL3ve1/75ieQlux9rg84bvn3Yl5ZvJmTh3bmngtGkqkulkQkwkItQDvjjU4EUA7sHaP9DeC34Q5KRES+FAg43l9dwvQPC/jg820kJ8RxwsAcHFBRXcfuPbVs2rWHyuo6yqvrqKippz7gQt5+nMEtpw7muhP6qoslEYmKUAvQ9UA3/30NcAqwADgW2BOZ0ERE2rbKmjr+vXAjD31YwNqSCjpnJnPzKYO4aHwvOqQlNfk95xzVdQEqa+qpqK6joqbOe6/eO/3l/Mrqek4YlMO4Ph2jeGQi0taFWoC+gNfx/BzgXuApM7sG6A78LkKxiYi0SZt27eGRjwt5au56SqvqGNEji3unjeK04V1DeiLdzEhJjCclMZ6OByhURURiJdSO6G8L+vycmRUBE4HVzrlXIhWciEhbsnD9TqbPLuD1pVtwznHq8C5cNSmP0b066NK4iLQqBy1AzSwReBz4qXPuCwDn3FxgboRjExFp9WrrA7yxdAsPzi7g06JdZKQkcNWkPC49tjc9OqTGOjwRkYg4aAHqnKs1s5OB2w62roiIhGZXZQ1PzSvi0Y8L2by7irzsNP737GF8Y3QP0pI1RoiItG6h/pZ7HjgPuCeCsYiItHqbygPc/sIS/r1wA1W1AY7r14k7zxnO5EG5xMXpMruItA2H8hT8HWb2NWA+UBG80Dn3h3AHJiLSmqwtKeeuV1fwzso9JCVs4JxR3bhiYh5DumbGOjQRkagLtQC9HNgJjPBfwRygAlREpBE1dQH++f4X/OW9NSQnxHFu/0Run3YC2enJsQ5NRCRmQn0KPi/SgYiItDYL1hy4zE0AACAASURBVO3ktucXs3prOWcc1ZVfnDmU5QvnqPgUkTZPd7qLiIRZaVUtv3tjFY/PXUfXzBT+delYvj60M/DlkHIiIm1ZSAWomf35QMudc98PTzgiIi3bm8u28POXllJcVs3lx/XhRycPIl1PtYuI7CfU34pHNZhOBAb7318Y1ohERFqgLbur+MXLS3lz2VYGd8ngn5eMZVTP9rEOS0SkWQr1HtDJDeeZWQrwIPBBuIMSEWkpAgHHE3PX8ds3VlFbH+DW0wZz1aQ8EuMPPmSmiEhbddjXhZxzVWZ2F/AmcF/4QhIRaRlWbSnjtucXs3D9Lib1z+auc4fTu1NarMMSEWn2jvTGpBwgPRyBiIi0FFW19fz13TXc9/4XZKQk8IcLRnLu0d01XruISIhCfQjphw1nAV2Bi4HXwh2UiEhz9fEX2/npC0so2FbBeaO7c8cZQ+mYlhTrsEREWpRQW0BvbDAdAEqAh4BfhzUiEZFmaFdlDXe/toIZ8zfQq2Mqj181gUkDsmMdlohIi6SO6EVEDsA5x8ufbeJXryxnZ2Ut383vx/enDKBdUnysQxMRabFCvQSfBMQ556oazE8BAs65mkgEJyISKxXVdby6eDNPfbKeRet3MbJHFo9eOYGh3TR2u4jIkQr1EvyzwPt8dcz364B84JwwxiQiEhPOOT7bsJtnPlnPy59uoqKmnn45afzqnOFcNL4X8XF6yEhEJBxCLUAnArc3Mv9t4KfhC0dEJPp2VtTwwqKNPPNJEau2ltEuMZ6pI7ryrXE9GdO7g55uFxEJs1AL0FSgrpH5ASAjfOGIiERHIOD46IvtPDO/iDeXbqGmPsDInu25+9yjOHNkVzJSEmMdoohIqxVqAboYuBD4RYP5FwFLwxqRiEgEbd69h+fmb+CZ+UVs2LmHrHaJXDShF98a15MhXXV/p4hINIRagP4KeNHM+gPv+vNOBL4JnBuJwEREwqW2PsA7K4p55pP1vL+6hICDif078ZNTB3Py0M6kJOqJdhGRaAq1G6ZXzexM4A7gz/7sRcBZzrnXIxWciMiR+KKknBmfFPHvhRvYVl5D58xkvpffnwvG9qRXp9RYhyci0maFPBSnc+4N4I0IxiIicsScc/x3RTEPzFrLvMIdxMcZJw7OZdr4nhw/IIeE+LhYhygi0uaF2g/oCQDOufcbme+cc7MiEJuISMgCAccby7bwl3fXsGJzKT07tuPW0wZz3uju5GakxDo8EREJEmoL6B+B/21kfibwS2DMkQZiZvHAfGCjc26qmeUBTwMdgYXAJerwXkQaqqsP8Mrizfz1vTWsKS6nb04av//mSM4e1U2tnSIizVSoBegg4LNG5i/xl4XDTcAKvKIW4LfAH51zT5vZfcBVwD/CtC8RaeFq6wO8sGgjf39vDYXbKxnUOYO/XHg0px/VVR3Gi4g0c6EWoHuAbkBBg/k9gCNulTSzHsAZwF3AD83r9XkKXjdPAI/gtbSqABVp46rr6nl2/gb+MfMLNu7aw/Dumdz37TGcPLQzcSo8RURaBHPOHXwlsyeAXnhPve/053UEXsS7ZH7hEQVh9hzwa7xO7X8MXA7Mcc7195f3BF53zg1v5LvXAtcC5OTkjJkxY8aRhNImlJeXk56eHuswWgTlKjTRyFN1veP9ojpeK6hlV7WjX1YcZ/VPZER2fIsaqUjnVGiUp9AoT6FTrkITzjxNnjx5gXNubGPLQm0B/TEwCyg0s8X+vBFACTDtSIIzs6lAsXNugZnl753dyKqNVsrOufuB+wEGDRrk8vPzG1tNgsycORPlKTTKVWgimaeK6joen7OOBz5ey7byGibkdeT7Jw7guH6dWlThuZfOqdAoT6FRnkKnXIUmWnkKtR/QzWY2ErgYGIVXID4CPIE3TvymI4hhInCWmZ0OpODdA/onoL2ZJTjn6vAu9R/JPkSkhSmtquWRDwt58MMCdlXW8rUB2dw4ZQDj8zrGOjQRETlCh9IPaCXwAICZdQeuAJYBvYHDHkbEOXcbcJu/3Xzgx865i83sWeB8vCfhLwNeOtx9iEjLsbOihoc+LOChjwopq6rjxMG53DClP0f36hDr0EREJExCLkD9bpLOAq4GTsYbH/4+4NnIhMYtwNNmdifeqEsPRmg/Im1OTV2Ae99ZzebdVWHZ3tYt1bxc/OkRb6e23vHuiq1U1NRz2vAuXD+5P8O7Z4UhQhERaU4OWoCa2SC8ovNSoAJ4EjgFr1/O5eEMxjk3E5jpf14LjA/n9kXE86tXlvPYnHV0b9+OcNxGWVVVz7o9O458Q8DXh3bm+sn9Gdg5IyzbExGR5ueABaiZfQAMB54DLtg7EpKZ3RKF2EQkAp6dX8Rjc9bxneP7ctvpQ8KyTd3cLyIih+JgLaDHAn8DHnDOLY1CPCISQUs37ub2F5dyXL9O3HxKuMaQEBEROTQHG6duLF6R+oGZLTKzH5hZlyjEJSJhtqOihu88toDstCT+cuHRGqZSRERi5oB/gZxznzrnrge6An8AzgaK/O+dYWZ6LFWkBairD3DjUwspKa/mvkvG0Ck9OdYhiYhIGxZSE4hzrso595hzLh8YAvwO+AGwxcxej2B8IhIG97y1mg/XbOfOs4czokf7WIcjIiJt3CFfg3POrXHO3Qr0BC4gDGPBi0jkvL5kM/e9/wUXTejFBeN6xjocERGR0PsBbcg5V4/XObw6iBdppj7fWsaPn/2Mo3u15xdnDo11OCIiIsBhtICKSMtQWlXLdx5bQLukeP5x8RiSEw57wDIREZGwOuwWUBFpvgIBx49mfMa6HZU8efUEumSlxDokERGRfdQCKtIK/X3mGt5evpXbTx/ChL6dYh2OiIjIflSAirQyM1cV8/u3V3P2qG5cMbFPrMMRERH5Cl2CF4kQ5xzz1+3k6XlFzF+3g2njenHlpD4RvRdz/fZKbnr6UwZ1zuDX5x2FhWOgdxERkTBTASoSZiVl1Ty/cAPPzC9ibUkF6ckJDOqSwW/fWMkzn6znZ1OHMmVwbtiLwz019Xzn8QU45/jnJWNITdI/bxERaZ70F0okDOoDjlmfl/DMvCL+u2IrdQHH2N4d+O75/ThjRFdSkxKYtbqE//nPMq56ZD75g3L42dSh9MtJD8v+nXPc9vxiVm4pZfrl4+jdKS0s2xUREYkEFaAiR6BoRyXPzi/i2QUb2Ly7ik5pSVw5KY8Lxvakf+7+xeXxA3N44/8dz6Mfr+NPb6/mlD/O4spJedw4pT8ZKYlHFMcjHxXy4qeb+NFJA5k8KPeItiUiIhJpKkBFDlF1XT1vLdvKjPlFzF6zDYATBubw86lDOXFIZ5ISmn62LzE+jqsm5XH2qG787o1VPPDBWp5fuJFbTh3EN0b3IC7u0C/LzyvYwZ2vruDrQzpz/eT+h31cIiIi0aICVCREq7aU8cwnRbywaAM7K2vp3r4d/+/EgZw/tgfd27c7pG1lpyfz2/NHcPExvfjly8u4+bnFPD53Pf9z1jBG9Qx9rPYtu6v43hML6dkxlT98a+RhFbAiIiLRpgJU5AD21Dmenreepz8p4tOiXSTGGycP68K0cT2Z2C/7iAu+ET3a89x1x/Hipxv59esrOedvH3L+mB785NRB5GYcuPP46rp6vvvEAipr6njymglkHuFlfBERkWhRASrSiN2Vtfzh7VU8Pa+S6volDMhN544zhnDe6B50TEsK677i4ozzRvfg5GFd+Ou7a3hw9lreWLqF75/Yn8uPy2vykv6vXlnOovW7+NtFoxnYOSOsMYmIiESSClCRIM45Xl2ymV++vJydlTUc1zWBH5w9nqN7to94n5rpyQncetpgvjWuJ796ZTl3v7aSp+cV8bMzh37lwaIZ84t4fM56vnN8X84Y0TWicYmIiISbRkIS8W3ctYerHpnPDU8uomtWCi9dP5GrjkpmdK8OUe3QPS87jemXj+Ohy8fhgCse+oSrHv6Ewm0VACzZsJs7XlzKxP6duPmUQVGLS0REJFzUAiptXn3A8fBHhfz+rVUA/GzqUC47tjcJ8XHM/Dx2cU0enMvE/tk89GEBf37nc07+4ywun9iHVxdvJic9mT9PO5qEeP0fUkREWh4VoNKmLdu0m9ueX8LiDbvJH5TDnecMp0eH1FiHtU9SQhzfOaEf5x7dnd++sYr7Z60lKSGO5647lk7pybEOT0RE5LCoAJU2aU9NPX96ZzX/+qCADqmJ/OXCo5k6omuzHTs9NzOF318wksuP60NtIMCIHqF31SQiItLcqACVNmfW6hJuf3EJRTv2MG1cT247bQhZqS2jC6OjemTFOgQREZEjpgJU2ozt5dXc+eoKXli0kb7ZaTx97TEc07dTrMMSERFpc1SASqvnnOPfCzdy56vLqaiu4/tT+vO9yf1JSYyPdWgiIiJtkgpQadUKt1Xw0xeW8NEX2xnbuwO/Pu8oBqjTdhERkZhSASqtUm19gAc+WMu9//2cpPg47jxnOBeN76Wx0kVERJoBFaDS6ixav5Pbnl/Cyi1lnDa8C788axidMw88rrqIiIhEjwpQaTWcc/x95hfc89YqOmekcP8lYzh5WJdYhyUiIiINqACVViEQcNz12goenF3AWSO7cde5w8lIaRldK4mIiLQ1KkClxaurD3DLv5fw74UbuPy4Pvx86lDd6ykiItKMqQCVFq2qtp4bnlzEf1ds5YcnDeTGKf2b7WhGIiIi4omLdQBm1tPM3jOzFWa2zMxu8ud3NLO3zexz/71DrGOV5qWsqpbLps/jvyu28r9nD+P7Jw5Q8SkiItICxLwABeqAHznnhgDHANeb2VDgVuAd59wA4B1/WgTwRjW68IE5LFi3k3unjeLSY/vEOiQREREJUcwLUOfcZufcQv9zGbAC6A6cDTzir/YIcE5sIpTmZuOuPXzzvo/5fGs5D1w6lrNHdY91SCIiInIIzDkX6xj2MbM+wCxgOLDeOdc+aNlO59xXLsOb2bXAtQA5OTljZsyYEZ1gW7Dy8nLS09NjHcZh2VQe4J75Veypc/xgTAoDO0R2OM2WnKtoUp5Cp1yFRnkKjfIUOuUqNOHM0+TJkxc458Y2tqzZFKBmlg68D9zlnHvezHaFUoAGGzRokFu1alWkQ23xZs6cSX5+fqzDOGSLN+zisunziI+L49ErxzO0W2bE99lScxVtylPolKvQKE+hUZ5Cp1yFJpx5MrMmC9CYX4IHMLNE4N/AE8655/3ZW82sq7+8K1Acq/gk9j5as40L759DWnICz113bFSKTxEREYmMmBeg5j22/CCwwjn3h6BFLwOX+Z8vA16KdmzSPLy5bAuXP/QJ3Tu049/fPY4+2WmxDklERESOQHPoB3QicAmwxMw+9ef9FPgNMMPMrgLWA9+MUXwSQzPmF3Hrvxczsmd7Hrp8HO1Tk2IdkoiIiByhmBegzrnZQFOdN54YzVikeXlg1lruem0FXxuQzT8vGUNqUsxPVxEREQkD/UWXZsc5x+/eXMXfZ37BGUd15Q/fGklyQmSfdhcREZHoUQEqzUp9wHHHi0t5at56LhzfizvPGU68xnUXERFpVVSASrNRUxfgB898yqtLNvO9/H7cfMogDa0pIiLSCqkAlWahorqO6x5fwAefb+P204dwzfF9Yx2SiIiIRIgKUImpzbv38N7KEp6Yu44Vm0v5v/NHcMHYnrEOS0RERCJIBahEVX3AsWj9Tt5dWcy7K4tZuaUMgO7t23Hft8dw8rAuMY5QREREIk0FqETczooa3l9dwnurinl/dQm7KmuJjzPG9u7AbacNZvLgXAbkput+TxERkTZCBaiEnXOO5ZtLmbmqhHdXFrNo/U4CDjqlJTFlcC5TBufytQE5ZLVLjHWoIiIiEgMqQCUsKqrr+HDNNt5bVcx7K0vYUloFwFHds7hhygCmDM5lRPcs4tSlkoiISJunAlQOW+G2Ct5dWcx7q4qZu3YHNfUB0pMTmNQ/mymDc8kflENuZkqswxQREZFmRgWohKymLsAnhTu8onNlMWu3VQDQNyeNS4/tzZTBuYzt05GkhLgYRyoiIiLNmQpQOaDi0ireW+U9sT77821U1NSTFB/HMf06cYlfdPbulBbrMEVERKQFUQEq+wkEHJ9t2MV7K4t5d1UxSzeWAtA1K4WzRnVnyuBcJvbvRGqSTh0RERE5PKoihN17apm1uoT3VnrdJG2vqCHOYHSvDtx8yiCmDM5lcJcMdZMkIiIiYaECtA1yzrF6a9m+zuAXrNtJfcDRPjWR/IE5TB6cy/EDcuiQlhTrUEVERKQVUgHaxry1bAu3z9pDyZuzABjSNZPrTujLlMG5jOrZgXh1kyQiIiIRpgK0jaiqrefu11bw6Mfr6JURx6/PG07+oBy6ZrWLdWgiIiLSxqgAbQPWFJdxw5OLWLmljKsm5XFM6lZOGt8r1mGJiIhIG6UOG1sx5xwzPinizL98SHFZNQ9dPo6fTR1Koi6zi4iISAypBbSVKq2q5fYXlvKfzzZxXL9O/PFbo+isUYlERESkGVAB2gp9WrSLG59ayKZdVdx8yiCuO6GfHi4SERGRZkMFaCsSCDju/2At97y5is6ZKcz4zjGM6d0x1mGJiIiI7EcFaCtRXFbFj2Z8xgefb+P0o7rw6/NGkNUuMdZhiYiIiHyFCtBWYNbqEn4441PKquq4+9yjuHB8T41aJCIiIs2WCtAjVF1XT0lZNcVl1RSXVlNSVvXl5/JqausDjO7VgQl5HTm6VwfaJcWHbd81dQF+/9Yq/jlrLQM7p/PkNccwsHNG2LYvIiIiEgkqQJtQXl1HcalfTJZVU1xaRUlZ9ZfFpl9o7qqs/cp34ww6pSeTm5FMwMFf3v2cex0kxhsjerRnfF5HJuR1ZEzvDmSkHN5l8vXbK7nx6UV8VrSLiyf04mdTh5KSGL7iVkRERCRSVIA2UFxWRf7vZlJZU/+VZUnxceRkJJObmUxedhoT8jqR60/nZCSTm5FCbkYyndKT93vqvLSqlgWFO5lbsIN5Bdt5YNZa/jHzC+IMhnXLYkJeR8bndWRcn44hjb/+8mebuP35JZjBPy4ezWlHdQ1rDkREREQiSQVoAx1Sk5g2rhe5mV4LZm5Gyr7PWe0SD+veysyURCYPzmXy4FwAKmvqWLR+F3PXbmduwQ4enbOOf80uAGBwlwy/hbQT4/I6kJvxZd+dlTV1/PLlZcyYv4ExvTtw77RR9OiQGp4DFxEREYkSFaANJMbH8fMzh0Z0H6lJCUzsn83E/tmAdx/pZ0W7mVfgFaTPLdjAox+vA6BvdhoT+nbkqO7teXD2WtZuq+DGKf256cQBJMRrICsRERFpeVSANgPJCfGM9y/D3wDU1gdYtqnUK0jX7uCVxZt5al4RnTOTeeLqCRzXLzvWIYuIiIgcNhWgzVBifByjerZnVM/2XHt8P+oDji9KyumalXLYDy2JiIiINBcqQFuA+DhT90oiIiLSaugmQhERERGJKhWgIiIiIhJVKkBFREREJKqadQFqZqea2SozW2Nmt8Y6HhERERE5cs22ADWzeOBvwGnAUOBCM4tsB50iIiIiEnHNtgAFxgNrnHNrnXM1wNPA2TGOSURERESOUHPuhqk7UBQ0vQGY0HAlM7sWuNafrDazpVGIraXLBrbFOogWQrkKjfIUOuUqNMpTaJSn0ClXoQlnnno3taA5F6CNDbruvjLDufuB+wHMbL5zbmykA2vplKfQKVehUZ5Cp1yFRnkKjfIUOuUqNNHKU3O+BL8B6Bk03QPYFKNYRERERCRMmnMB+gkwwMzyzCwJmAa8HOOYREREROQINdtL8M65OjO7AXgTiAemO+eWHeRr90c+slZBeQqdchUa5Sl0ylVolKfQKE+hU65CE5U8mXNfua1SRERERCRimvMleBERERFphVSAioiIiEhUtZoCVMN2Ns7MeprZe2a2wsyWmdlN/vyOZva2mX3uv3eIdazNgZnFm9kiM3vFn84zs7l+np7xH4hr88ysvZk9Z2Yr/XPrWJ1TX2VmP/D/3S01s6fMLEXnlMfMpptZcXDfzU2dQ+b5s//7fbGZjY5d5NHVRJ5+5//bW2xmL5hZ+6Blt/l5WmVmp8Qm6thoLFdBy35sZs7Msv1pnVMN8mRmN/rnzTIz+7+g+RE5p1pFAaphOw+oDviRc24IcAxwvZ+bW4F3nHMDgHf8aYGbgBVB078F/ujnaSdwVUyian7uBd5wzg0GRuLlTOdUEDPrDnwfGOucG473MOU0dE7t9TBwaoN5TZ1DpwED/Ne1wD+iFGNz8DBfzdPbwHDn3AhgNXAbgP+7fRowzP/O3/2/j23Fw3w1V5hZT+AkYH3QbJ1TQcxsMt5okyOcc8OAe/z5ETunWkUBiobtbJJzbrNzbqH/uQyvUOiOl59H/NUeAc6JTYTNh5n1AM4A/uVPGzAFeM5fRXkCzCwTOB54EMA5V+Oc24XOqcYkAO3MLAFIBTajcwoA59wsYEeD2U2dQ2cDjzrPHKC9mXWNTqSx1VienHNvOefq/Mk5eP1kg5enp51z1c65AmAN3t/HNqGJcwrgj8BP2H8wG51T+/su8BvnXLW/TrE/P2LnVGspQBsbtrN7jGJptsysD3A0MBfo7JzbDF6RCuTGLrJm4094v6QC/nQnYFfQL3qdV56+QAnwkH+7wr/MLA2dU/txzm3Ea0VYj1d47gYWoHPqQJo6h/Q7vmlXAq/7n5WnBszsLGCjc+6zBouUq/0NBL7m3x70vpmN8+dHLE+tpQANadjOtszM0oF/A//POVca63iaGzObChQ75xYEz25kVZ1XXqveaOAfzrmjgQra+OX2xvj3L54N5AHdgDS8y34N6Zw6OP1bbISZ3Y53m9UTe2c1slqbzZOZpQK3Az9vbHEj89psrvB+r3fAu1XvZmCGfxUwYnlqLQWohu08ADNLxCs+n3DOPe/P3rr3coP/XtzU99uIicBZZlaIdwvHFLwW0fb+5VPQebXXBmCDc26uP/0cXkGqc2p/XwcKnHMlzrla4HngOHROHUhT55B+xzdgZpcBU4GL3ZcdeitP++uH9x/Az/zf7T2AhWbWBeWqoQ3A8/4tCfPwrgRmE8E8tZYCVMN2NsH/H8yDwArn3B+CFr0MXOZ/vgx4KdqxNSfOuduccz2cc33wzp93nXMXA+8B5/urtfk8ATjntgBFZjbIn3UisBydUw2tB44xs1T/3+HePOmcalpT59DLwKX+k8vHALv3Xqpvi8zsVOAW4CznXGXQopeBaWaWbGZ5eA/YzItFjM2Bc26Jcy7XOdfH/92+ARjt/w7TObW/F/EaXjCzgUASsI1InlPOuVbxAk7HexrwC+D2WMfTXF7AJLzm8sXAp/7rdLz7G98BPvffO8Y61ubyAvKBV/zPff1/bGuAZ4HkWMfXHF7AKGC+f169iHfpRufUV/P0P8BKYCnwGJCsc2pfbp7Cuze2Fq8wuKqpcwjvMuDf/N/vS/B6Foj5McQwT2vw7svb+zv9vqD1b/fztAo4LdbxxzpXDZYXAtk6pxo9p5KAx/3fVQuBKZE+pzQUp4iIiIhEVWu5BC8iIiIiLYQKUBERERGJKhWgIiIiIhJVKkBFREREJKpUgIqIiIhIVKkAFZE2yczizWy6me0wM+f3BShhZGaD/dwOj3UsItK8qAAVkajyC5IDvR6OUijn4g06cCrQFW+c9iNmZr8xs/nh2JaISGuVcPBVRETCqmvQ56nAAw3m7YlSHP2BIucNO9csmVmSc64m1nE0N8qLSMunFlARiSrn3Ja9L2BXw3nOud0AZna0mc00sz1mtt3M/mVmGXu3Y2ZPm9lzZvY/ZlZsZqVmdr+ZJR8sBjN7Gvg1MNBvdV3pz48zs9vNrMDf72Izu6DBd/9gZp/7ywvM7C5/CGDM7Dq8IRLHBLXoTjOzFP/z1Abb2mJmN/if965zrZm9bGYVwM/9ZUeZ2RtmVm5mW83scTPLCSXfQXm62cw2+7l8IDhPZjbHzO5p7HsN1vmTmf3ZzHb5Of+umbXz877bzNaZ2bcaCWOYmX1sZlVmtszMJjfY1wGPL+gYfmZmm/BGZRGRFkwFqIg0O2aWCbwJFAPjgG/ijVN8X4NVT8FryZyMdzn9LOBXIeziO8Bv8YY07Io3ZC3A74CL/OVDgd8Dj5jZ14O+uxu4FBgCfB+4Arj5/7d3PyFWVmEcx78/bdKBFhFitZBsBtIih2ISJAxpYWnIEKVBi1pIi+jPEAQR4qZoIRbEZIlUVlLYJJMEJRGFgkkGE5l/KBFCS6oprYXZH6ecp8U5I2+vd2bu3Jm5c5t+H3gX57zPPfec9w7Dw3nPed98bgvwPLA/t3s56VWlo/EksB1YALwkaQ6wG+gF2vOYZ+WYai0F5pKu0z2ka/XAKPsFsBroI/0mz5JeZfg2abw3AN3AqxWS4/Wka3s9sAd4V9JsgFGM71bSa0yXAstr6LuZNZLJfiepDx8+/r8HsDL9Gzqv/mHgJNBcqFsGDABzcrkbOAHMLMTcB/wOXFjFd68FDhfKFwP9wMJS3CZg+zDtPAIcKpTXAZ+VYmYCAawo1fcBD5Vini7FrAd2lOouy7FtVYyzmzRjOK1Q9zrwXqH8KfBMhc/1lGJ2FcrTSMn4tkJdc/6NVuTy/NzPRwsx00nv5F5b7fhyX74Dmib7b9aHDx/jc3gNqJk1oquBfRFRXA+6B1A+dzzX7YuIPwsxe0lJ0FzgyCi/cwHQBOySVKxvAg4PFiTdTUqQW4CLSGvpx3M9YnkDUztwk6TTFWJbgQNVtHkoIgYK5e+BeTX07dx3RcSApJPAwULdH5J+BWaXPre3EHNWUi9phhmqH9+BiPirhj6bWQNyAmpmjUikGbBKhqofq8ElSctIM5NF/QCSlpBmD9cCH5FmAFeR12oOYzD5U6m+qULsbxX69Q6wpkJsuZ9DKSduwb+XYA0M0bfyta7Uzkhtj6Ta8ZWvi5n9hzkBNbNGgzTm0QAAAhpJREFU9CWwSlJzYRZ0MSm5OVyIu07SjIg4k8uLSLvoj9XwnQeBv0m3+PcMEbMY+Doi1g1WSJpbiukn3WY+JyL6JZ2isNs/r328pIp+fU5Kio9GxNkq4mtxotS3aUAbaW3neFgEfJLbnk5aL/pKPleP8ZlZg/EmJDNrRFtIs3KvSbo275p+AXgzIo4X4pqBlyVdI2k58BSwMWp4RE9E/AJ0AV2S7pXUmnfiPyhpdQ47Alwp6a58vhO4s9TUMaBVUpukWYM75IGdQGdusx3YDJxhZF2k5HCrpIWSWiTdImlzoe2x2gl0SLpN0jzgOc6/jT4WnZJulzSftElrNvBiPleP8ZlZg3ECamYNJyJOkXY9X0raHd0D7ALuL4V+AHxD2kW9DdhBuj1eq8dIm4jWAF/l9juAo/l8D7AB2Ah8QZoRfaLUxlukhG43aWbxjlzfCfwAfEzaVLOB/Biq4UTEt8CNwAzgQ+AQKUE8DYzXjOEmYCvwRu5fH/D+OLUN8Djpmu4HlgAdEfEj1G18ZtZgFDFRy6nMzCZOfpbnBRGxcrL7YmZmo+MZUDMzMzOrK29CMrMpR9JVpM0tQ2mJiJ/q1Z+Jkt9m9PMwITdHRG+9+mNmVi3fgjezKUdSE3DFMCFTYse10gNLW4cJOV54QoCZWcNwAmpmZmZmdeU1oGZmZmZWV05AzczMzKyunICamZmZWV05ATUzMzOzuvoHREBKihp/I1YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 792x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = draw_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Channel 개수 별  Accuracy 정도 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 5.0),\n",
       " (10, 5.833333333333333),\n",
       " (15, 3.75),\n",
       " (20, 10.0),\n",
       " (25, 12.5),\n",
       " (30, 14.999999999999996),\n",
       " (35, 22.916666666666664),\n",
       " (40, 28.333333333333332),\n",
       " (45, 31.66666666666667),\n",
       " (50, 26.666666666666668),\n",
       " (55, 37.49999999999999),\n",
       " (60, 37.5),\n",
       " (65, 37.5),\n",
       " (70, 41.66666666666667),\n",
       " (75, 45.0),\n",
       " (80, 50.416666666666664),\n",
       " (85, 54.166666666666664),\n",
       " (90, 53.75),\n",
       " (95, 60.41666666666667),\n",
       " (100, 60.0),\n",
       " (105, 63.74999999999999),\n",
       " (110, 65.0),\n",
       " (115, 67.91666666666667),\n",
       " (120, 72.08333333333333),\n",
       " (125, 71.25),\n",
       " (130, 73.33333333333334),\n",
       " (135, 77.08333333333334),\n",
       " (140, 77.91666666666666),\n",
       " (145, 80.41666666666666),\n",
       " (150, 84.16666666666666),\n",
       " (155, 82.5),\n",
       " (160, 84.16666666666669)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 채널별 feature가 각 주파수 별로 important가 몇인지 dataframe으로 정리하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>delta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>theta</th>\n",
       "      <th>Rank</th>\n",
       "      <th>max_value</th>\n",
       "      <th>max_channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ch2</th>\n",
       "      <td>0.038243</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.008358</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.011720</td>\n",
       "      <td>0.005410</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011720</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch4</th>\n",
       "      <td>0.038197</td>\n",
       "      <td>0.008456</td>\n",
       "      <td>0.006796</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.006961</td>\n",
       "      <td>0.006226</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch10</th>\n",
       "      <td>0.037350</td>\n",
       "      <td>0.011166</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>0.009180</td>\n",
       "      <td>0.006761</td>\n",
       "      <td>0.004992</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.011166</td>\n",
       "      <td>alpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch3</th>\n",
       "      <td>0.036777</td>\n",
       "      <td>0.007024</td>\n",
       "      <td>0.007805</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.006424</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch26</th>\n",
       "      <td>0.036120</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.007452</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.011115</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.011115</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch27</th>\n",
       "      <td>0.036094</td>\n",
       "      <td>0.007773</td>\n",
       "      <td>0.006016</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>0.009762</td>\n",
       "      <td>0.006054</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.009762</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch6</th>\n",
       "      <td>0.035408</td>\n",
       "      <td>0.005130</td>\n",
       "      <td>0.008045</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.008045</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch1</th>\n",
       "      <td>0.034890</td>\n",
       "      <td>0.008599</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.005395</td>\n",
       "      <td>0.005062</td>\n",
       "      <td>0.007799</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.008599</td>\n",
       "      <td>alpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch28</th>\n",
       "      <td>0.034258</td>\n",
       "      <td>0.006928</td>\n",
       "      <td>0.006040</td>\n",
       "      <td>0.006560</td>\n",
       "      <td>0.008973</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.008973</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch29</th>\n",
       "      <td>0.034134</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>0.005463</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch5</th>\n",
       "      <td>0.033903</td>\n",
       "      <td>0.005443</td>\n",
       "      <td>0.008339</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.008035</td>\n",
       "      <td>0.008137</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.008339</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch14</th>\n",
       "      <td>0.033592</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>0.009078</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.009078</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch17</th>\n",
       "      <td>0.033384</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.008239</td>\n",
       "      <td>0.007222</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.008239</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch30</th>\n",
       "      <td>0.033235</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.008148</td>\n",
       "      <td>0.008786</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.008786</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch20</th>\n",
       "      <td>0.032905</td>\n",
       "      <td>0.007678</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.008469</td>\n",
       "      <td>0.007034</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.008469</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch13</th>\n",
       "      <td>0.032598</td>\n",
       "      <td>0.006581</td>\n",
       "      <td>0.005647</td>\n",
       "      <td>0.009863</td>\n",
       "      <td>0.004734</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.009863</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch9</th>\n",
       "      <td>0.032597</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>0.006828</td>\n",
       "      <td>0.005570</td>\n",
       "      <td>0.005651</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>alpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch21</th>\n",
       "      <td>0.031762</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.005458</td>\n",
       "      <td>0.009463</td>\n",
       "      <td>0.005113</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.009463</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch32</th>\n",
       "      <td>0.030994</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.005425</td>\n",
       "      <td>0.005608</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>theata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch8</th>\n",
       "      <td>0.030665</td>\n",
       "      <td>0.007265</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>0.005157</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch11</th>\n",
       "      <td>0.030411</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>0.005421</td>\n",
       "      <td>0.009169</td>\n",
       "      <td>0.005820</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.009169</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch24</th>\n",
       "      <td>0.030242</td>\n",
       "      <td>0.005603</td>\n",
       "      <td>0.005616</td>\n",
       "      <td>0.005072</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch22</th>\n",
       "      <td>0.029918</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.005432</td>\n",
       "      <td>0.005223</td>\n",
       "      <td>0.008210</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.008210</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch25</th>\n",
       "      <td>0.029794</td>\n",
       "      <td>0.005183</td>\n",
       "      <td>0.006115</td>\n",
       "      <td>0.007760</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>0.005108</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.007760</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch15</th>\n",
       "      <td>0.029576</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.006363</td>\n",
       "      <td>0.005894</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch23</th>\n",
       "      <td>0.029136</td>\n",
       "      <td>0.006242</td>\n",
       "      <td>0.004337</td>\n",
       "      <td>0.006129</td>\n",
       "      <td>0.006738</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.006738</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch31</th>\n",
       "      <td>0.029126</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>0.007486</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.007486</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch7</th>\n",
       "      <td>0.027534</td>\n",
       "      <td>0.005241</td>\n",
       "      <td>0.005720</td>\n",
       "      <td>0.003699</td>\n",
       "      <td>0.009268</td>\n",
       "      <td>0.003606</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.009268</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch16</th>\n",
       "      <td>0.026188</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>0.006672</td>\n",
       "      <td>0.004976</td>\n",
       "      <td>0.003969</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.006672</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch12</th>\n",
       "      <td>0.025986</td>\n",
       "      <td>0.005908</td>\n",
       "      <td>0.003196</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>0.005466</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch19</th>\n",
       "      <td>0.024984</td>\n",
       "      <td>0.004304</td>\n",
       "      <td>0.005202</td>\n",
       "      <td>0.006737</td>\n",
       "      <td>0.003837</td>\n",
       "      <td>0.004904</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.006737</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>alpha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         total     alpha      beta     delta     gamma     theta  Rank  \\\n",
       "Ch2   0.038243  0.008152  0.008358  0.004603  0.011720  0.005410   1.0   \n",
       "Ch4   0.038197  0.008456  0.006796  0.009758  0.006961  0.006226   2.0   \n",
       "Ch10  0.037350  0.011166  0.005250  0.009180  0.006761  0.004992   3.0   \n",
       "Ch3   0.036777  0.007024  0.007805  0.006325  0.009200  0.006424   4.0   \n",
       "Ch26  0.036120  0.006452  0.007452  0.004147  0.011115  0.006954   5.0   \n",
       "Ch27  0.036094  0.007773  0.006016  0.006489  0.009762  0.006054   6.0   \n",
       "Ch6   0.035408  0.005130  0.008045  0.008019  0.007489  0.006726   7.0   \n",
       "Ch1   0.034890  0.008599  0.008034  0.005395  0.005062  0.007799   8.0   \n",
       "Ch28  0.034258  0.006928  0.006040  0.006560  0.008973  0.005756   9.0   \n",
       "Ch29  0.034134  0.007338  0.005463  0.006726  0.009397  0.005210  10.0   \n",
       "Ch5   0.033903  0.005443  0.008339  0.003949  0.008035  0.008137  11.0   \n",
       "Ch14  0.033592  0.005391  0.004335  0.008244  0.009078  0.006544  12.0   \n",
       "Ch17  0.033384  0.007435  0.006617  0.003870  0.008239  0.007222  13.0   \n",
       "Ch30  0.033235  0.005199  0.006382  0.008148  0.008786  0.004720  14.0   \n",
       "Ch20  0.032905  0.007678  0.002468  0.008469  0.007034  0.007256  15.0   \n",
       "Ch13  0.032598  0.006581  0.005647  0.009863  0.004734  0.005774  16.0   \n",
       "Ch9   0.032597  0.008236  0.006312  0.006828  0.005570  0.005651  17.0   \n",
       "Ch21  0.031762  0.004783  0.006945  0.005458  0.009463  0.005113  18.0   \n",
       "Ch32  0.030994  0.004943  0.005425  0.005608  0.006902  0.008116  19.0   \n",
       "Ch8   0.030665  0.007265  0.005621  0.004831  0.007791  0.005157  20.0   \n",
       "Ch11  0.030411  0.003652  0.006348  0.005421  0.009169  0.005820  21.0   \n",
       "Ch24  0.030242  0.005603  0.005616  0.005072  0.007680  0.006270  22.0   \n",
       "Ch22  0.029918  0.005297  0.005432  0.005223  0.008210  0.005756  23.0   \n",
       "Ch25  0.029794  0.005183  0.006115  0.007760  0.005628  0.005108  24.0   \n",
       "Ch15  0.029576  0.004933  0.005537  0.006849  0.006363  0.005894  25.0   \n",
       "Ch23  0.029136  0.006242  0.004337  0.006129  0.006738  0.005689  26.0   \n",
       "Ch31  0.029126  0.005117  0.006050  0.007486  0.005596  0.004876  27.0   \n",
       "Ch7   0.027534  0.005241  0.005720  0.003699  0.009268  0.003606  28.0   \n",
       "Ch16  0.026188  0.004795  0.005777  0.006672  0.004976  0.003969  29.0   \n",
       "Ch12  0.025986  0.005908  0.003196  0.004473  0.006942  0.005466  30.0   \n",
       "Ch19  0.024984  0.004304  0.005202  0.006737  0.003837  0.004904  31.0   \n",
       "Ch18  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  32.0   \n",
       "\n",
       "      max_value max_channel  \n",
       "Ch2    0.011720       gamma  \n",
       "Ch4    0.009758       delta  \n",
       "Ch10   0.011166       alpha  \n",
       "Ch3    0.009200       gamma  \n",
       "Ch26   0.011115       gamma  \n",
       "Ch27   0.009762       gamma  \n",
       "Ch6    0.008045        beta  \n",
       "Ch1    0.008599       alpha  \n",
       "Ch28   0.008973       gamma  \n",
       "Ch29   0.009397       gamma  \n",
       "Ch5    0.008339        beta  \n",
       "Ch14   0.009078       gamma  \n",
       "Ch17   0.008239       gamma  \n",
       "Ch30   0.008786       gamma  \n",
       "Ch20   0.008469       delta  \n",
       "Ch13   0.009863       delta  \n",
       "Ch9    0.008236       alpha  \n",
       "Ch21   0.009463       gamma  \n",
       "Ch32   0.008116      theata  \n",
       "Ch8    0.007791       gamma  \n",
       "Ch11   0.009169       gamma  \n",
       "Ch24   0.007680       gamma  \n",
       "Ch22   0.008210       gamma  \n",
       "Ch25   0.007760       delta  \n",
       "Ch15   0.006849       delta  \n",
       "Ch23   0.006738       gamma  \n",
       "Ch31   0.007486       delta  \n",
       "Ch7    0.009268       gamma  \n",
       "Ch16   0.006672       delta  \n",
       "Ch12   0.006942       gamma  \n",
       "Ch19   0.006737       delta  \n",
       "Ch18   0.000000       alpha  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_important =important[0:32]+important[32:64]+important[64:96]+important[96:128]+important[128:160]\n",
    "\n",
    "alpha =[]\n",
    "beta = []\n",
    "delta = []\n",
    "gamma = []\n",
    "theta = []\n",
    "total = []\n",
    "value =[]\n",
    "value1 =[]\n",
    "max_value =[]\n",
    "\n",
    "for i in range(len(important[0:32])):\n",
    "    alpha.append(important[0:32][i])\n",
    "    beta.append(important[32:64][i])\n",
    "    delta.append(important[64:96][i])\n",
    "    gamma.append(important[96:128][i])\n",
    "    theta.append(important[128:160][i])\n",
    "    total.append(channel_important[i])\n",
    "\n",
    "\n",
    "for i in range(len(channel_list)):\n",
    "    value.append(list(zip([total[i],alpha[i],beta[i],delta[i],gamma[i],theta[i]])))\n",
    "    value1.append(list(zip([alpha[i],beta[i],delta[i],gamma[i],theta[i]])))\n",
    "\n",
    "for i in range(len(channel_list)):\n",
    "    max_value.append(max(np.array(value1).reshape(32,5).tolist()[i]))\n",
    "\n",
    "    \n",
    "value = np.array(value).reshape(32,6).tolist()    \n",
    "rank_data = list(zip(channel_list,value))\n",
    "channel_df = pd.DataFrame(value,index=channel_list, columns=[\"total\",\"alpha\",\"beta\",\"delta\",\"gamma\",\"theta\"])\n",
    "channel_df[\"Rank\"] = channel_df[\"total\"].rank(ascending=False)\n",
    "channel_df[\"max_value\"] = max_value\n",
    "\n",
    "\n",
    "channel_df.sort_values(\"total\",ascending=False ,inplace = True)\n",
    "channel_df.name = (\"Feature importance\")\n",
    "a = []\n",
    "for i in range(len(channel_list)):\n",
    "    if channel_df[channel_df.columns[1]][channel_df.index[i]] == channel_df[\"max_value\"][channel_df.index[i]]:\n",
    "        a.append(\"alpha\")\n",
    "    elif channel_df[channel_df.columns[2]][channel_df.index[i]] == channel_df[\"max_value\"][channel_df.index[i]]:\n",
    "        a.append(\"beta\")\n",
    "    elif channel_df[channel_df.columns[3]][channel_df.index[i]] == channel_df[\"max_value\"][channel_df.index[i]]:\n",
    "        a.append(\"delta\")\n",
    "    elif channel_df[channel_df.columns[4]][channel_df.index[i]] == channel_df[\"max_value\"][channel_df.index[i]]:\n",
    "        a.append(\"gamma\")\n",
    "    elif channel_df[channel_df.columns[5]][channel_df.index[i]] == channel_df[\"max_value\"][channel_df.index[i]]:\n",
    "        a.append(\"theata\")\n",
    "channel_df[\"max_channel\"] = a\n",
    "\n",
    "\n",
    "print(channel_df.name)\n",
    "channel_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nose, Mouse로 training 시키고 O2가 무엇으로 분류되는지 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### task 0 1 2 : 1-back  2-back  rest\n",
    "\n",
    "### eye 0  1    : close eye     open eye\n",
    "\n",
    "### respiratory 0 1 2 : mouse nose o2 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_csv_3():\n",
    "    normalize_power = str(input(\"Relative, Abs :\"))\n",
    "    excel_dir = \"./EEG_data\" + '/' + normalize_power\n",
    "    excel_list = sorted(glob.glob(excel_dir+'/[!~]*.xlsx'))\n",
    "    \n",
    "    subject = int(input(\"subject :\"))\n",
    "    book = Workbook()\n",
    "    sheet = book.active\n",
    "    sheet.cell(row=1, column=161).value = 'target'\n",
    " \n",
    "    # x축 생성   \n",
    "    for i in range(1,33):\n",
    "        sheet.cell(row=1, column=i).value = 'ACh' + str(i)\n",
    "        sheet.cell(row=1, column=i+32).value = 'BCh' + str(i)\n",
    "        sheet.cell(row=1, column=i+64).value = 'DCh' + str(i)\n",
    "        sheet.cell(row=1, column=i+96).value = 'GCh' + str(i)\n",
    "        sheet.cell(row=1, column=i+128).value = 'TCh' + str(i)\n",
    "        \n",
    "    # 파일을 순차적으로 열어서 셀 영역을 복사\n",
    "    for j in range(0,5):\n",
    "        wb = openpyxl.load_workbook(excel_list[j], data_only=True)\n",
    "        wb_sheet = wb.sheetnames\n",
    "        for k in range(0,12):\n",
    "            source = wb[wb_sheet[k]]\n",
    "            for l in range(2, 22):\n",
    "                for m in range(2, 34):\n",
    "                    sheet.cell(row=20*k+l,column=32*j+m-1).value = source.cell(row=l,column=m).value\n",
    "        \n",
    "\n",
    "    with open('./dataset_eeg_3.csv', 'w', newline=\"\") as f:\n",
    "        c = csv.writer(f)\n",
    "        for r in sheet.rows:\n",
    "            c.writerow([cell.value for cell in r])\n",
    "            \n",
    "    df = pd.read_csv('./dataset_eeg_3.csv')\n",
    "    df[df =='                      NaN'] =np.nan\n",
    "    df = df.fillna(0.0).astype('float64')\n",
    "    pd.options.mode.chained_assignment = None\n",
    "\n",
    "    df[\"target\"][0*subject:1*subject] = \"0\"\n",
    "    df[\"target\"][1*subject:2*subject] = \"1\"\n",
    "    df[\"target\"][2*subject:3*subject] = \"2\"\n",
    "\n",
    "    df[\"target\"][3*subject:4*subject] = \"0\"\n",
    "    df[\"target\"][4*subject:5*subject] = \"1\"\n",
    "    df[\"target\"][5*subject:6*subject] = \"2\"\n",
    "\n",
    "    df[\"target\"][6*subject:7*subject] = \"0\"\n",
    "    df[\"target\"][7*subject:8*subject] = \"1\"\n",
    "    df[\"target\"][8*subject:9*subject] = \"2\"\n",
    "\n",
    "    df[\"target\"][9*subject:10*subject] = \"0\"\n",
    "    df[\"target\"][10*subject:11*subject] = \"1\"\n",
    "    df[\"target\"][11*subject:12*subject] = \"2\"\n",
    "    df.astype('float64')\n",
    "    df.to_csv('./dataset_eeg_3.csv')\n",
    "    \n",
    "    return df\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Relative, Abs : Relative\n",
      "subject : 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whbom\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "eeg_data_3 = dataset_csv_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "state={}\n",
    "\n",
    "state[\"1back_mouse\"]=eeg_data_3.iloc[0:20]\n",
    "state[\"1back_nose\"]=eeg_data_3.iloc[20:40]\n",
    "state[\"1back_O2\"]=eeg_data_3.iloc[40:60]\n",
    "\n",
    "state[\"2back_mouse\"]=eeg_data_3.iloc[60:80]\n",
    "state[\"2back_nose\"]=eeg_data_3.iloc[80:100]\n",
    "state[\"2back_O2\"]=eeg_data_3.iloc[100:120]\n",
    "\n",
    "state[\"close_rest_mouse\"]=eeg_data_3.iloc[120:140]\n",
    "state[\"close_rest_nose\"]=eeg_data_3.iloc[140:160]\n",
    "state[\"close_rest_O2\"]=eeg_data_3.iloc[160:180]\n",
    "\n",
    "state[\"open_rest_mouse\"]=eeg_data_3.iloc[180:200]\n",
    "state[\"open_rest_nose\"]=eeg_data_3.iloc[200:220]\n",
    "state[\"open_rest_O2\"]=eeg_data_3.iloc[220:2400]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = {}\n",
    "ds_test = {}\n",
    "\n",
    "\n",
    "ds_train={\"1back_mouse\":state[\"1back_mouse\"], \n",
    "       \"1back_nose\":state[\"1back_nose\"],\n",
    "       \"1back_O2\":state[\"1back_O2\"],\n",
    "       \"1back_m_n\":state[\"1back_mouse\"].append(state[\"1back_nose\"]),\n",
    "       \"1back\":state[\"1back_mouse\"].append(state[\"1back_nose\"]).append(state[\"1back_O2\"]),\n",
    "       \n",
    "                                               \n",
    "       \"2back_mouse\":state[\"2back_mouse\"],\n",
    "       \"2back_nose\":state[\"2back_nose\"],\n",
    "       \"2back_O2\":state[\"2back_O2\"],\n",
    "       \"2back_m_n\":state[\"2back_mouse\"].append(state[\"2back_nose\"]),\n",
    "       \"2back\":state[\"2back_mouse\"].append(state[\"2back_nose\"]).append(state[\"2back_O2\"]),\n",
    "       \n",
    "       \"close_rest_mouse\":state[\"close_rest_mouse\"], \n",
    "       \"close_rest_nose\":state[\"close_rest_nose\"],\n",
    "       \"close_rest_O2\":state[\"close_rest_O2\"],\n",
    "       \"close_rest_m_n\":state[\"close_rest_mouse\"].append(state[\"close_rest_nose\"]),\n",
    "       \"close_rest\":state[\"close_rest_mouse\"].append(state[\"close_rest_nose\"]).append(state[\"close_rest_O2\"]),\n",
    "       \n",
    "       \"open_rest_mouse\":state[\"open_rest_mouse\"],\n",
    "       \"open_rest_nose\":state[\"open_rest_nose\"],\n",
    "       \"open_rest_O2\":state[\"open_rest_O2\"],\n",
    "       \"open_rest_m_n\":state[\"open_rest_mouse\"].append(state[\"open_rest_nose\"]),\n",
    "       \"open_rest\":state[\"open_rest_mouse\"].append(state[\"open_rest_nose\"]).append(state[\"open_rest_O2\"]),\n",
    "       \n",
    "       \n",
    "       \"total_mouse\" : state[\"1back_mouse\"].append(state[\"2back_mouse\"]).append(state[\"close_rest_mouse\"]).append(state[\"open_rest_mouse\"]),\n",
    "       \"total_nose\" : state[\"1back_nose\"].append(state[\"2back_nose\"]).append(state[\"close_rest_nose\"]).append(state[\"open_rest_nose\"]),\n",
    "       \"total_O2\" : state[\"1back_O2\"].append(state[\"2back_O2\"]).append(state[\"close_rest_O2\"]).append(state[\"open_rest_O2\"]),\n",
    "       \"total_m_n\": state[\"1back_mouse\"].append(state[\"1back_nose\"]).append(state[\"2back_mouse\"]).append(state[\"2back_nose\"]).append(state[\"close_rest_mouse\"]).append(state[\"close_rest_nose\"]).append(state[\"open_rest_mouse\"]).append(state[\"open_rest_nose\"]),\n",
    "       \"total\": state[\"1back_mouse\"].append(state[\"1back_nose\"]).append(state[\"1back_O2\"]).append(state[\"2back_mouse\"]).append(state[\"2back_nose\"]).append(state[\"2back_O2\"]).append(state[\"close_rest_mouse\"]).append(state[\"close_rest_nose\"]).append(state[\"close_rest_O2\"]).append(state[\"open_rest_mouse\"]).append(state[\"open_rest_nose\"]).append(state[\"open_rest_O2\"])\n",
    "       \n",
    "       \n",
    "      }\n",
    "\n",
    "ds_test = {\"1back_mouse\":state[\"1back_mouse\"], \n",
    "       \"1back_nose\":state[\"1back_nose\"],\n",
    "       \"1back_O2\":state[\"1back_O2\"],\n",
    "       \"1back_m_n\":state[\"1back_mouse\"].append(state[\"1back_nose\"]),\n",
    "       \"1back\":state[\"1back_mouse\"].append(state[\"1back_nose\"]).append(state[\"1back_O2\"]),\n",
    "       \n",
    "                                               \n",
    "       \"2back_mouse\":state[\"2back_mouse\"],\n",
    "       \"2back_nose\":state[\"2back_nose\"],\n",
    "       \"2back_O2\":state[\"2back_O2\"],\n",
    "       \"2back_m_n\":state[\"2back_mouse\"].append(state[\"2back_nose\"]),\n",
    "       \"2back\":state[\"2back_mouse\"].append(state[\"2back_nose\"]).append(state[\"2back_O2\"]),\n",
    "       \n",
    "       \"close_rest_mouse\":state[\"close_rest_mouse\"], \n",
    "       \"close_rest_nose\":state[\"close_rest_nose\"],\n",
    "       \"close_rest_O2\":state[\"close_rest_O2\"],\n",
    "       \"close_rest_m_n\":state[\"close_rest_mouse\"].append(state[\"close_rest_nose\"]),\n",
    "       \"close_rest\":state[\"close_rest_mouse\"].append(state[\"close_rest_nose\"]).append(state[\"close_rest_O2\"]),\n",
    "       \n",
    "       \"open_rest_mouse\":state[\"open_rest_mouse\"],\n",
    "       \"open_rest_nose\":state[\"open_rest_nose\"],\n",
    "       \"open_rest_O2\":state[\"open_rest_O2\"],\n",
    "       \"open_rest_m_n\":state[\"open_rest_mouse\"].append(state[\"open_rest_nose\"]),\n",
    "       \"open_rest\":state[\"open_rest_mouse\"].append(state[\"open_rest_nose\"]).append(state[\"open_rest_O2\"]),\n",
    "        \n",
    "        \n",
    "               \n",
    "       \"total_mouse\" : state[\"1back_mouse\"].append(state[\"2back_mouse\"]).append(state[\"close_rest_mouse\"]).append(state[\"open_rest_mouse\"]),\n",
    "        \"total_nose\" : state[\"1back_nose\"].append(state[\"2back_nose\"]).append(state[\"close_rest_nose\"]).append(state[\"open_rest_nose\"]),\n",
    "       \"total_O2\" : state[\"1back_O2\"].append(state[\"2back_O2\"]).append(state[\"close_rest_O2\"]).append(state[\"open_rest_O2\"]),\n",
    "       \"total_m_n\": state[\"1back_mouse\"].append(state[\"1back_nose\"]).append(state[\"2back_mouse\"]).append(state[\"2back_nose\"]).append(state[\"close_rest_mouse\"]).append(state[\"close_rest_nose\"]).append(state[\"open_rest_mouse\"]).append(state[\"open_rest_nose\"]),\n",
    "        \"total\": state[\"1back_mouse\"].append(state[\"1back_nose\"]).append(state[\"1back_O2\"]).append(state[\"2back_mouse\"]).append(state[\"2back_nose\"]).append(state[\"2back_O2\"]).append(state[\"close_rest_mouse\"]).append(state[\"close_rest_nose\"]).append(state[\"close_rest_O2\"]).append(state[\"open_rest_mouse\"]).append(state[\"open_rest_nose\"]).append(state[\"open_rest_O2\"])\n",
    "\n",
    "       }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA_RF_M_N_O2 (tasks, k_parameter, num_iter):\n",
    "\n",
    "#     for mode in ['no_lda','lda']:\n",
    "    for mode in ['lda']:\n",
    "        for task_train,task_test in tasks:\n",
    "\n",
    "            print('-------------------')\n",
    "            print('training:{}/test:{}/mode:{}'.format(task_train,task_test,mode))\n",
    "            train_3 = ds_train[task_train]\n",
    "            test_3  = ds_test[task_test]\n",
    "\n",
    "            X = np.array(train_3.iloc[:,0:-1])\n",
    "            Y = np.array(train_3['target'])\n",
    "\n",
    "            rnd_clf = RandomForestClassifier(n_estimators=1000, n_jobs=-1)\n",
    "\n",
    "            all_scores = []\n",
    "            Mouse = 0\n",
    "            Nose = 0\n",
    "            for idx in range(num_iter):\n",
    "                skf = StratifiedKFold(n_splits=k_parameter, shuffle=True)\n",
    "                skf.get_n_splits(X,Y)\n",
    "\n",
    "                for train_index, test_index in skf.split(X,Y):\n",
    "\n",
    "                    X_final = X\n",
    "                    lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "                    if(mode == 'lda') : \n",
    "                        lda.fit(X,Y)\n",
    "#                         X_final = X\n",
    "                        X_final = lda.transform(X)\n",
    "                    \n",
    "\n",
    "                    rnd_clf.fit(X_final[train_index], Y[train_index])\n",
    "                    val_mae = rnd_clf.score(X_final[test_index],Y[test_index])\n",
    "                    all_scores.append(val_mae)\n",
    "\n",
    "                    test = np.array(test_3.iloc[:,0:-1])\n",
    "                    if mode == 'lda':\n",
    "#                         pass\n",
    "                        test = lda.transform(test)\n",
    "\n",
    "                    aaa = rnd_clf.predict(test)\n",
    "\n",
    "                    Mouse = Mouse+np.count_nonzero(aaa=='0')\n",
    "                    Nose = Nose+ np.count_nonzero(aaa=='1')\n",
    "\n",
    "            print('model_score:{}'.format(np.mean(all_scores)))\n",
    "            print('mouse:{}({:.2}), nose:{}({:.2}) / total:{}'.format(Mouse,Mouse/(Mouse+Nose),Nose,Nose/(Mouse+Nose),(Mouse+Nose)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_RF_M_N_O2 (tasks, k_parameter, num_iter):\n",
    "\n",
    "#     for mode in ['no_lda','lda']:\n",
    "    for mode in ['pca']:\n",
    "        for task_train,task_test in tasks:\n",
    "\n",
    "            print('-------------------')\n",
    "            print('training:{}/test:{}/mode:{}'.format(task_train,task_test,mode))\n",
    "            train_3 = ds_train[task_train]\n",
    "            test_3  = ds_test[task_test]\n",
    "\n",
    "            X = np.array(train_3.iloc[:,0:-1])\n",
    "            Y = np.array(train_3['target'])\n",
    "\n",
    "            rnd_clf = RandomForestClassifier(n_estimators=1000,max_depth= None, n_jobs=-1,class_weight=\"balanced\" )\n",
    "#             rnd_clf = RandomForestClassifier(n_estimators=1000,max_features= 160,n_jobs=-1 )\n",
    "\n",
    "            all_scores = []\n",
    "            Mouse = 0\n",
    "            Nose = 0\n",
    "            for idx in range(num_iter):\n",
    "                skf = StratifiedKFold(n_splits=k_parameter, shuffle=True)\n",
    "                skf.get_n_splits(X,Y)\n",
    "\n",
    "                for train_index, test_index in skf.split(X,Y):\n",
    "\n",
    "                    X_final = X\n",
    "                    pca = PCA(n_components=0.8)\n",
    "                    if(mode == 'pca') : \n",
    "                        pca.fit(X,Y)\n",
    "                        X_final = pca.transform(X)\n",
    "#                         X_final = X\n",
    "                    \n",
    "\n",
    "                    rnd_clf.fit(X_final[train_index], Y[train_index])\n",
    "                    val_mae = rnd_clf.score(X_final[test_index],Y[test_index])\n",
    "                    all_scores.append(val_mae)\n",
    "\n",
    "                    test = np.array(test_3.iloc[:,0:-1])\n",
    "                    if mode == 'pca':\n",
    "#                         pass\n",
    "                        test = pca.transform(test)\n",
    "\n",
    "                    aaa = rnd_clf.predict(test)\n",
    "\n",
    "                    Mouse = Mouse+np.count_nonzero(aaa=='0')\n",
    "                    Nose = Nose+ np.count_nonzero(aaa=='1')\n",
    "\n",
    "            print('model_score:{}'.format(np.mean(all_scores)))\n",
    "            print('mouse:{}({:.2}), nose:{}({:.2}) / total:{}'.format(Mouse,Mouse/(Mouse+Nose),Nose,Nose/(Mouse+Nose),(Mouse+Nose)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
